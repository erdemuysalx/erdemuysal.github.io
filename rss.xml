<?xml version="1.0" encoding="iso-8859-1"?>
<rss version="2.0"><channel><title>erdo.dev RSS Feed</title><link>https://www.erdo.dev</link><description>The official RSS Feed for https://www.erdo.dev</description><lastBuildDate>Fri, 27 Jun 2025 12:39:34 GMT</lastBuildDate><generator>PyRSS2Gen-1.1.0</generator><docs>http://blogs.law.harvard.edu/tech/rss</docs><item><title>Running ROS Across Multiple Machines</title><link>https://www.erdo.dev/blog/2022-04-15_Running_ROS_Across_Multiple_Machines/</link><description>&lt;h1&gt;Running ROS Across Multiple Machines&lt;/h1&gt;
&lt;p&gt;15 Apr 2022&lt;/p&gt;
&lt;p&gt;The Robot Operating System (ROS) is an open-source framework widely used in robotics research and development for building, developing, and deploying robot software. In both development and deployment, there may be situations where you need to access a robot's computational resources remotely. For example, in multi-robot systems, individual robots often need to communicate over a shared network to collaboratively solve tasks. To enable this, ROS instances running on different machines must be configured to communicate, provided that all machines are connected to the same network.&lt;/p&gt;
&lt;p&gt;This tutorial will walk you through the process of setting up ROS to communicate over a local area network (LAN) with multiple machines. This setup is useful for creating a network of machines - whether they represent robots or workstations - working together under ROS.&lt;/p&gt;
&lt;h2&gt;Configuring ROS for LAN Communication&lt;/h2&gt;
&lt;p&gt;To properly configure ROS across multiple machines in a LAN, consider the following key points:
* Only one master is needed, so choose a single machine to run &lt;code&gt;roscore&lt;/code&gt;.
* All nodes must be set to use the same master by configuring the &lt;code&gt;ROS_MASTER_URI&lt;/code&gt; environment variable.
* Bi-directional connectivity between all machines is crucial for communication.
* Each machine must advertise itself using a hostname that all other machines can resolve.&lt;/p&gt;
&lt;p&gt;For example, let's say you're connecting your workstation to a robot to retrieve and store sensor readings. In this setup, we'll refer to the machines as the robot (master) and the workstation (slave). The robot and workstation will have symbolic IP addresses of &lt;code&gt;192.168.0.1&lt;/code&gt; and &lt;code&gt;192.168.0.2&lt;/code&gt;, respectively.&lt;/p&gt;
&lt;h3&gt;Testing Network Connectivity&lt;/h3&gt;
&lt;p&gt;To verify that both the master and slave are connected to the same network, you can use the &lt;code&gt;ping&lt;/code&gt; command. Open a terminal on either machine and ping the IP address of the other device to check connectivity.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Robot (master):&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;ping 192.168.0.2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Workstation (slave):&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;ping 192.168.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Testing Port Connectivity&lt;/h3&gt;
&lt;p&gt;For full connectivity, machines must be able to communicate over all necessary ports. To ensure this, you can use the &lt;code&gt;netcat&lt;/code&gt; (&lt;code&gt;nc&lt;/code&gt;) command in the terminal of either machine as shown below:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Robot (master):&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;netcat -l 1234
netcat 192.168.0.2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Workstation (slave):&lt;/strong&gt; &lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;netcat -l 1234
netcat 192.168.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Configuring Name Resolution&lt;/h3&gt;
&lt;p&gt;For machines to communicate effectively over the network, they must have addressable names, typically in the form of hostnames. Follow the steps below to configure name resolution from the terminal of each machine:&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Robot (master):&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;export ROS_IP=192.168.0.1
export ROS_HOSTNAME=192.168.0.1
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Workstation (slave):&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;export ROS_IP=192.168.0.2
export ROS_HOSTNAME=192.168.0.2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Alternatively, you can modify the &lt;code&gt;/etc/hosts&lt;/code&gt; file on each machine to manually associate hostnames with their corresponding IP addresses. This file serves as a local directory that instructs each machine on how to resolve specific hostnames into IP addresses, ensuring reliable communication between machines on the network.&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;sudo nano /etc/hosts
192.168.0.1 robot
192.168.0.2 workstation
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now, we can refer to the machines by their hostnames, robot and workstation, for communication.&lt;/p&gt;
&lt;h2&gt;Connecting Machines in LAN&lt;/h2&gt;
&lt;p&gt;Once all configurations are in place, the machines are ready to communicate with each other over the network, enabling seamless interaction and data exchange.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Robot (master):&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;export ROS_MASTER_URI=http://robot:11311 
roscore &amp;amp;&amp;amp; rosrun rospy_tutorials listener.py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Workstation (slave):&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;export ROS_MASTER_URI=http://robot:11311 
rosrun rospy_tutorials talker.py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this article, we covered how to configure ROS to run across multiple machines, enabling seamless communication over a network. I hope this guide proves useful in setting up your ROS projects and facilitates efficient multi-machine operations.&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;[1] &lt;a href="https://wiki.ros.org/ROS/Tutorials/MultipleMachines"&gt;https://wiki.ros.org/ROS/Tutorials/MultipleMachines&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href="https://wiki.ros.org/ROS/NetworkSetup#Configuring_.2Fetc.2Fhosts"&gt;https://wiki.ros.org/ROS/NetworkSetup#Configuring_.2Fetc.2Fhosts&lt;/a&gt;&lt;/p&gt;</description><pubDate>Fri, 15 Apr 2022 12:00:00 GMT</pubDate></item><item><title>SLAM and Navigation in ROS</title><link>https://www.erdo.dev/blog/2022-03-07_SLAM_and_Navigation_in_ROS/</link><description>&lt;h1&gt;SLAM and Navigation in ROS&lt;/h1&gt;
&lt;p&gt;07 Mar 2022&lt;/p&gt;
&lt;p&gt;Can you imagine a robot that cannot locate itself, map its surroundings, or navigate? Such a robot would hardly be useful. These essential capabilities make robots indispensable in many applications. But does every robotics software developer need to be an expert in SLAM (Simultaneous Localization and Mapping) and navigation, which are distinct research areas, to implement these features? Fortunately, the answer is no, thanks to ROS.&lt;/p&gt;
&lt;p&gt;In this article, we will explore how to tackle complex tasks such as SLAM and navigation using ROS. Even if these topics are not directly applicable to your specific robot, I believe this guide will serve as a valuable starting point and help you build a solid technical foundation.&lt;/p&gt;
&lt;h2&gt;SLAM and Navigation Using ROS&lt;/h2&gt;
&lt;p&gt;While SLAM and navigation are complex and challenging fields, ROS simplifies them conceptually and provides algorithms that can be integrated into your robotics application with minimal adjustments. Some commonly used algorithms and nodes include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="http://wiki.ros.org/amcl"&gt;amcl&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://wiki.ros.org/gmapping"&gt;gmapping&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="http://wiki.ros.org/move_base"&gt;move_base&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Behind the scenes, ROS processes data from odometry and sensors, such as LiDAR or cameras, converting this information into velocity commands that are sent to the robot's controller. However, implementing ROS's navigation algorithms on an arbitrary robot can be more involved. Before starting navigation, the robot must be running ROS, have a properly configured TF transform tree, and publish odometry and sensor data using the appropriate ROS message types.&lt;/p&gt;
&lt;h2&gt;Essential Requirements for Effective Robot Navigation&lt;/h2&gt;
&lt;p&gt;Before a robot can navigate effectively, several prerequisites must be met to ensure smooth operation and accurate performance. These include:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;URDF (Universal Robot Description File)&lt;/strong&gt;: The robot's URDF must be error-free, as it provides a detailed description of the robot's physical structure, which is essential for proper navigation.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Localization:&lt;/strong&gt; The robot needs to know its exact position relative to its environment. This can be achieved using various sensors, such as LiDAR or cameras, to accurately localize the robot.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Obstacle Avoidance:&lt;/strong&gt; During navigation, unexpected obstacles may appear. The robot should be capable of detecting and dynamically avoiding these obstacles in real-time.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Path Planning:&lt;/strong&gt; To move from point A to point B, the robot must be able to calculate an efficient and collision-free route using path planning algorithms.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Configuring the Robot for the ROS Navigation Stack&lt;/h2&gt;
&lt;p&gt;The ROS Navigation Stack comprises several essential components that work together to enable a robot to move autonomously. Each component plays a critical role in ensuring accurate localization, path planning, and motion control. Below is an explanation of the key components in the navigation stack:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Sensor Transforms (tf):&lt;/strong&gt; The data collected from various sensors must be referenced to a common frame, typically base_link, to accurately compare information from different sensors. The robot should publish the relationship between its main coordinate frame and its sensors' frames using ROS tf.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Sensor Sources:&lt;/strong&gt; Sensors serve two main purposes in navigation: localizing the robot on the map (e.g., using a laser scanner) and detecting obstacles in its path (using lasers, sonars, or point clouds).&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Odometry Source:&lt;/strong&gt; Odometry data provides the robot's position relative to its starting point. The main sources of odometry are wheel encoders, IMUs, and 2D/3D cameras (for visual odometry). The odometry value must be published to the navigation stack using the nav_msgs/Odometry message type, which can contain both the robot's position and velocity.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Base Controller:&lt;/strong&gt; The base controller's primary function is to take the output of the navigation stack (a geometry_msgs/Twist message) and convert it into motor commands, setting the robot's velocity to execute the desired motion.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="ROS navigation stack" src="https://wiki.ros.org/navigation/Tutorials/RobotSetup?action=AttachFile&amp;amp;do=get&amp;amp;target=overview_tf_small.png" /&gt;&lt;/p&gt;
&lt;p&gt;If you haven't done so already, create a new package named robot_navigation inside the workspace ros_ws:&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;cd .../ros_ws/src
catkin_create_pkg robot_navigation std_msgs roscpp
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Implementing SLAM Using the gmapping ROS Node&lt;/h3&gt;
&lt;p&gt;ROS provides powerful tools to assist in the SLAM process, such as acml and gmapping, for enabling robots to understand and navigate their environments which uses SLAM techniques to build a map from sensor data. Below are the steps required to configure and run the gmappingnode for SLAM purposes.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1.&lt;/strong&gt; Create a new file named &lt;code&gt;gmapping.launch&lt;/code&gt; in the package &lt;code&gt;robot_navigation&lt;/code&gt;, located in the folder &lt;code&gt;.../robot_navigation/launch&lt;/code&gt;. Paste the code below into gmapping.launch:&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;&amp;lt;launch&amp;gt;

&amp;lt;arg name=&amp;quot;use_gazebo&amp;quot; default=&amp;quot;false&amp;quot; /&amp;gt;

&amp;lt;!-- Gazebo --&amp;gt;
&amp;lt;group if=&amp;quot;$(arg use_gazebo)&amp;quot;&amp;gt;
    &amp;lt;param name=&amp;quot;use_sim_time&amp;quot; value=&amp;quot;true&amp;quot; /&amp;gt;
    &amp;lt;include file=&amp;quot;$(find robot_bringup)/launch/robot.launch&amp;quot;&amp;gt;
        &amp;lt;arg name=&amp;quot;world&amp;quot; value=&amp;quot;maze&amp;quot; /&amp;gt;
    &amp;lt;/include&amp;gt;
&amp;lt;/group&amp;gt;

&amp;lt;!-- SLAM --&amp;gt;
&amp;lt;node pkg=&amp;quot;gmapping&amp;quot; type=&amp;quot;slam_gmapping&amp;quot; name=&amp;quot;gmapping&amp;quot;&amp;gt;
    &amp;lt;param name=&amp;quot;base_frame&amp;quot;            value=&amp;quot;base_link&amp;quot;/&amp;gt;
    &amp;lt;param name=&amp;quot;odom_frame&amp;quot;            value=&amp;quot;odom&amp;quot; /&amp;gt;
    &amp;lt;param name=&amp;quot;map_update_interval&amp;quot;   value=&amp;quot;3.0&amp;quot;/&amp;gt;
    &amp;lt;param name=&amp;quot;maxUrange&amp;quot;             value=&amp;quot;15.0&amp;quot;/&amp;gt;
&amp;lt;/node&amp;gt;

&amp;lt;!-- Teleoperation - keyboard control --&amp;gt;
&amp;lt;node pkg=&amp;quot;teleop_twist_keyboard&amp;quot; type=&amp;quot;teleop_twist_keyboard.py&amp;quot; name=&amp;quot;teleop_twist_keyboard&amp;quot; output=&amp;quot;screen&amp;quot;/&amp;gt;

&amp;lt;/launch&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Step 2.&lt;/strong&gt; Configure parameters such as &lt;code&gt;base_frame, odom_frame, map_update_interval, maxUrange&lt;/code&gt; manually in the launch file according to your hardware. Alternatively, you can write parameters into the gmapping.yaml file and link it to the launch file:&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;&amp;lt;rosparam file=&amp;quot;$(find gmapping_package)/launch/gmapping.yaml&amp;quot; command=&amp;quot;load&amp;quot;/&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Step 3.&lt;/strong&gt; Launch the gmapping node:&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;roslaunch robot_navigation gmapping.launch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Step 4.&lt;/strong&gt; Track the map in RViz: &lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;rosrun rviz rviz
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Step 5.&lt;/strong&gt; Using the teleop_twist_keyboard node and your PC's keyboard, drive the mobile robot around to build a complete map of the environment in which it operates.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 6.&lt;/strong&gt; Once the mapping is complete, save the map:&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;rosrun map_server map_saver -f map
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will generate two files:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;A PGM image file of the map&lt;/li&gt;
&lt;li&gt;A YAML file containing metadata about the map&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;strong&gt;Step 7.&lt;/strong&gt; To make the map available to other nodes, serve the map data by running the following ROS service:&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;rosrun map_server map_server map.yaml
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;This will create two topics: &lt;code&gt;/map&lt;/code&gt; and &lt;code&gt;/map_metadata&lt;/code&gt;, which other nodes can subscribe to.&lt;/p&gt;
&lt;h3&gt;Implementing Navigation Using move_base ROS Node&lt;/h3&gt;
&lt;p&gt;In ROS, path planning is performed using the occupancy map, previously generated by the gmapping node. The next step is to create a cost map, which allows for the calculation of an optimal trajectory. Once the best path is identified, appropriate control mechanisms can be applied to follow the path efficiently. Both path planning and velocity control are managed by the move_base node. This node utilizes two cost maps-one for the global planner and another for the local planner (from the &lt;a href="https://wiki.ros.org/costmap_2d"&gt;costmap_2d&lt;/a&gt; package). These components need to be properly configured to enable the move_base node to function effectively. Below are the steps to configure and run the move_base node for navigation.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Step 1.&lt;/strong&gt; The first component of the move_base node is the cost map. The cost map is a grid where each cell is assigned a value representing the "cost" based on its distance from obstacles. The closer the obstacle, the higher the cost. Two types of costs are used:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Global Cost Map: Helps the global planner calculate the shortest path between two points using previously gathered sensor data.&lt;/li&gt;
&lt;li&gt;Local Cost Map: Assists the local planner in dynamically controlling smaller sections of the path.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To configure the costmap parameters, create and edit the following files.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;/robot_navigation/config/costmap_common.yaml&lt;/code&gt; for common cost map parameters:&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;global_frame: map
robot_base_frame: base_link
footprint: [[0.14, 0.14], [0.14, -0.14], [-0.14, -0.14], [-0.14, 0.14]]
rolling_window: true

inflation_radius: 0.5
cost_scaling_factor: 4.0

track_unknown_space: true
observation_sources: scan
scan: {sensor_frame: laser, data_type: LaserScan, topic: scan, marking: true, clearing: true}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;/robot_navigation/config/costmap_global.yaml&lt;/code&gt; for global cost map parameters:&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;global_costmap:
    update_frequency: 2.0
    publish_frequency: 1.0

    obstacle_range: 5.0
    raytrace_range: 5.0
    static_map: true

    width: 15.0
    height: 15.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;/robot_navigation/config/costmap_local.yaml&lt;/code&gt; for local cost map parameters:&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;local_costmap:
    update_frequency: 5.0
    publish_frequency: 2.0

    obstacle_range: 2.5
    raytrace_range: 2.5
    static_map: false

    width: 2.5
    height: 2.5
    resolution: 0.02
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Step 2.&lt;/strong&gt; The second component of the move_base node is the planner. The planner's role is to reach the target position while avoiding obstacles within a user-defined tolerance. It uses the costmap to generate a path through the cells with the lowest cost. The move_base node utilizes two planners:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Global Planner: Finds the optimal path using the global costmap.&lt;/li&gt;
&lt;li&gt;Local Planner: Selects controls to guide the robot along the path by adjusting velocities.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Configure the planner parameters in the following files:&lt;/p&gt;
&lt;p&gt;&lt;code&gt;/robot_navigation/config/planner_global.yaml&lt;/code&gt; for global planner parameters:&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;base_global_planner : navfn/NavfnROS
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;code&gt;/robot_navigation/config/planner_local.yaml&lt;/code&gt; for local planner parameters:&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;base_local_planner: base_local_planner/TrajectoryPlannerROS

TrajectoryPlannerROS:
    min_vel_x: 0.1
    max_vel_x: 0.3
    min_vel_theta: -0.7
    max_vel_theta: 0.7
    min_in_place_vel_theta: 0.4
    escape_vel: -0.1

    acc_lim_theta: 1.0
    acc_lim_x: 1.0

    holonomic_robot: false

    xy_goal_tolerance: 0.1
    yaw_goal_tolerance: 0.2

    meter_scoring: true
    path_distance_bias: 20
    goal_distance_bias: 15
    occdist_scale:  0.01

    sim_time: 2.0
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Step 3.&lt;/strong&gt; Now that the cost maps and planners are configured, create a new file named &lt;code&gt;move_base.launch&lt;/code&gt; in the &lt;code&gt;robot_navigation&lt;/code&gt; package, located in the folder &lt;code&gt;.../robot_navigation/launch&lt;/code&gt;. Insert the following code into &lt;code&gt;move_base.launch&lt;/code&gt;:&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;&amp;lt;launch&amp;gt;

&amp;lt;arg name=&amp;quot;use_gazebo&amp;quot; default=&amp;quot;false&amp;quot; /&amp;gt;
&amp;lt;arg name=&amp;quot;map_name&amp;quot; default=&amp;quot;map.yaml&amp;quot;/&amp;gt;

&amp;lt;!-- Localization --&amp;gt;
&amp;lt;include file=&amp;quot;$(find robot_navigation)/launch/gmapping.launch&amp;quot;&amp;gt;
    &amp;lt;arg name=&amp;quot;use_gazebo&amp;quot; value=&amp;quot;$(arg use_gazebo)&amp;quot; /&amp;gt;
    &amp;lt;arg name=&amp;quot;map_name&amp;quot; default=&amp;quot;$(arg map_name)&amp;quot;/&amp;gt;
&amp;lt;/include&amp;gt;

&amp;lt;!-- Path planning --&amp;gt;
&amp;lt;node pkg=&amp;quot;move_base&amp;quot; type=&amp;quot;move_base&amp;quot; respawn=&amp;quot;false&amp;quot; name=&amp;quot;move_base&amp;quot; output=&amp;quot;screen&amp;quot;&amp;gt;
    &amp;lt;rosparam file=&amp;quot;$(find robot_navigation)/config/move_base.yaml&amp;quot; command=&amp;quot;load&amp;quot; /&amp;gt;
    &amp;lt;rosparam file=&amp;quot;$(find robot_navigation)/config/costmap_common.yaml&amp;quot; command=&amp;quot;load&amp;quot; ns=&amp;quot;global_costmap&amp;quot; /&amp;gt;
    &amp;lt;rosparam file=&amp;quot;$(find robot_navigation)/config/costmap_common.yaml&amp;quot; command=&amp;quot;load&amp;quot; ns=&amp;quot;local_costmap&amp;quot; /&amp;gt;
    &amp;lt;rosparam file=&amp;quot;$(find robot_navigation)/config/costmap_global.yaml&amp;quot; command=&amp;quot;load&amp;quot; /&amp;gt;
    &amp;lt;rosparam file=&amp;quot;$(find robot_navigation)/config/costmap_local.yaml&amp;quot; command=&amp;quot;load&amp;quot; /&amp;gt;
    &amp;lt;rosparam file=&amp;quot;$(find robot_navigation)/config/planner_global.yaml&amp;quot; command=&amp;quot;load&amp;quot; /&amp;gt;
    &amp;lt;rosparam file=&amp;quot;$(find robot_navigation)/config/planner_local.yaml&amp;quot; command=&amp;quot;load&amp;quot; /&amp;gt;
&amp;lt;/node&amp;gt;

&amp;lt;node pkg=&amp;quot;rviz&amp;quot; type=&amp;quot;rviz&amp;quot; name=&amp;quot;rviz&amp;quot; args=&amp;quot;-d $(find robot_navigation)/rviz/move_base.rviz&amp;quot;/&amp;gt;

&amp;lt;/launch&amp;gt;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Step 4.&lt;/strong&gt; Launch the move_base node:&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;roslaunch robot_navigation move_base.launch
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;In this article, we covered the essential steps to set up SLAM and navigation in ROS using the gmappingand the move_base nodes. By leveraging ROS's navigation stack, you can create autonomous robots capable of localization, mapping, and navigation in dynamic environments. While additional tuning might be required for specific applications, this guide provides an introductory foundation to get you started on your ROS navigation journey.&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;[1] &lt;a href="https://wiki.ros.org/navigation/Tutorials/RobotSetup"&gt;https://wiki.ros.org/navigation/Tutorials/RobotSetup&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href="https://wiki.ros.org/map_server"&gt;https://wiki.ros.org/map_server&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[3] &lt;a href="http://wiki.ros.org/costmap_2d"&gt;http://wiki.ros.org/costmap_2d&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[4] &lt;a href="https://husarion.com/tutorials/ros-tutorials/8-slam/"&gt;https://husarion.com/tutorials/ros-tutorials/8-slam/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[5] &lt;a href="https://husarion.com/tutorials/ros-tutorials/9-navigation/#cost-map"&gt;https://husarion.com/tutorials/ros-tutorials/9-navigation/#cost-map&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[6] &lt;a href="https://web.fs.uni-lj.si/lampa/rosin/ROS%20Summer%20School/Day%203/mapping/#"&gt;https://web.fs.uni-lj.si/lampa/rosin/ROS%20Summer%20School/Day%203/mapping/#&lt;/a&gt;&lt;/p&gt;</description><pubDate>Mon, 07 Mar 2022 12:00:00 GMT</pubDate></item><item><title>ROS File System</title><link>https://www.erdo.dev/blog/2022-02-12_ROS-File-System/</link><description>&lt;h1&gt;ROS File System&lt;/h1&gt;
&lt;p&gt;12 Feb 2022&lt;/p&gt;
&lt;p&gt;The Robot Operating System (ROS) is a flexible and powerful platform for developing software components for robotic systems. At its core, ROS operates through a network of nodes that communicate with each other, with these nodes organized into packages. These packages follow a specific file system convention recommended by Open Robotics, the organization behind ROS. A package serves as a root directory containing all the ROS-related files necessary for a particular project. In this article, we will explore the ROS file system and what you can expect to find within these packages. Understanding the ROS file system is crucial for the efficient development and organization of robotic software.&lt;/p&gt;
&lt;h2&gt;ROS Package&lt;/h2&gt;
&lt;p&gt;At the most fundamental level, nodes are the smallest executable building blocks of ROS. These nodes are designed to carry out specific tasks, such as control, navigation, and more, and they communicate with each other through messages. Nodes that serve similar purposes are typically grouped within a ROS package. A node generally consists of source code, messages, and services.&lt;/p&gt;
&lt;h2&gt;Manifest Files&lt;/h2&gt;
&lt;p&gt;ROS packages contain important files known as manifests, such as &lt;code&gt;package.xml&lt;/code&gt; and &lt;code&gt;CMakeLists.txt&lt;/code&gt;, which provide metadata and essential information about the ROS node.&lt;/p&gt;
&lt;h3&gt;package.xml&lt;/h3&gt;
&lt;p&gt;This file defines properties about the package such as the package name, version numbers, authors, maintainers, and dependencies on other catkin packages. Every single ROS node must contain one &lt;code&gt;package.xml&lt;/code&gt; file.&lt;/p&gt;
&lt;h3&gt;CMakeLists.txt&lt;/h3&gt;
&lt;p&gt;This file serves as an input to the CMake build system, which is used for building software packages. Any CMake-compliant package contains one or more &lt;code&gt;CMakeLists.txt&lt;/code&gt; files that describe how to compile the code and where to install it. The &lt;code&gt;CMakeLists.txt&lt;/code&gt; file used in a Catkin project is essentially a standard CMakeLists file with a few additional constraints. Like package.xml, every ROS package must include a &lt;code&gt;CMakeLists.txt&lt;/code&gt; file.&lt;/p&gt;
&lt;h2&gt;Source Code and Assets&lt;/h2&gt;
&lt;p&gt;Source code files that are part of ROS nodes, typically written in C++ or Python, should be placed in a folder named &lt;code&gt;src&lt;/code&gt;, which is specifically designated for source code. Any script files that are not directly part of a node should be stored in a separate &lt;code&gt;scripts&lt;/code&gt; folder.&lt;/p&gt;
&lt;p&gt;Descriptions of request and response data structures for services provided by each ROS process are stored in the &lt;code&gt;srv&lt;/code&gt; folder. Similarly, custom messages used by nodes should be placed in the &lt;code&gt;msg&lt;/code&gt; folder.&lt;/p&gt;
&lt;p&gt;Files that define how to start a ROS node are called launch files, and these are essential for initiating ROS nodes as specified. The ROS core uses these launch files to start the nodes.&lt;/p&gt;
&lt;p&gt;The Gazebo simulation tool requires certain asset files, such as &lt;code&gt;.world&lt;/code&gt; files and .urdf files. The &lt;code&gt;.world&lt;/code&gt; files define the 3D simulation environment, while the &lt;code&gt;.urdf&lt;/code&gt; files specify the robot model. These files should be placed in the &lt;code&gt;worlds&lt;/code&gt; folder.&lt;/p&gt;
&lt;p&gt;The overall folder structure typically looks as follows:&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;└── dummy_ros_pkg
├── README.md
├── CMakeLists.txt
├── package.xml
├── launch
│   └── robot.launch
├── worlds
│   └── sim.world
└── src
    ├── foo_node.cpp
    └── bar_node.py
│
└── scripts
        ├── foo_scipt.py
        └── bar_script.py
│
├── msg
        └── dummy.msg
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;[1] &lt;a href="https://hub.packtpub.com/ros-architecture-and-concepts/#:~:text=Similar%20to%20an%20operating%20system,create%20a%20program%20within%20ROS."&gt;https://hub.packtpub.com/ros-architecture-and-concepts/#:~:text=Similar%20to%20an%20operating%20system,create%20a%20program%20within%20ROS.&lt;/a&gt;&lt;/p&gt;</description><pubDate>Sat, 12 Feb 2022 12:00:00 GMT</pubDate></item><item><title>ROS Conceptual Design Patters</title><link>https://www.erdo.dev/blog/2022-01-27_ROS-Conceptual-Design-Patterns/</link><description>&lt;h1&gt;ROS Conceptual Design Patters&lt;/h1&gt;
&lt;p&gt;27 Jan 2022&lt;/p&gt;
&lt;p&gt;Throughout my career, I've had the opportunity to work with robotics on several occasions, and it has become a passion of mine. This enthusiasm has inspired me to start a new series of articles focused on robotics. In this series, I will primarily concentrate on robotics software and control, rather than the hardware aspects.&lt;/p&gt;
&lt;p&gt;To kick off this series, I decided to write an introductory article on the Robot Operating System (ROS). Although there are already many resources available on ROS, I believe that providing an overview will be a fitting way to begin this journey into robotics.&lt;/p&gt;
&lt;p&gt;The content of this article will cover the following topics:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Overview of ROS&lt;/li&gt;
&lt;li&gt;ROS Concepts and Design Patterns&lt;/li&gt;
&lt;li&gt;ROS vs ROS 2&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="NASA Opportunity Mars Exploration Rover. The figure is taken from https://www.jpl.nasa.gov/missions/mars-exploration-rover-opportunity-mer/" src="https://cdn-images-1.medium.com/max/800/1*9qtOzaq_LiIJ33lqaw5X8g.jpeg" /&gt;&lt;/p&gt;
&lt;h2&gt;Overview of ROS&lt;/h2&gt;
&lt;p&gt;What exactly is ROS? Despite what its name might suggest, ROS is not a traditional operating system. While it provides utility functions similar to those of a general-purpose operating system - such as hardware abstraction, low-level hardware control, interprocess message-passing, and package management - it is a middleware suite, not a true operating system.&lt;/p&gt;
&lt;p&gt;As a middleware suite, ROS offers developers a collection of software frameworks, libraries, and tools designed to facilitate the development of robust robotics applications that can integrate with diverse hardware and software clusters.ROS Concepts and Design Patterns&lt;/p&gt;
&lt;h2&gt;Understanding ROS Conceptual Design Patterns&lt;/h2&gt;
&lt;p&gt;This subtitle introduces the reader to the conceptual design patterns within the ROS framework and provides context for the detailed explanations that follow.&lt;/p&gt;
&lt;h3&gt;Nodes&lt;/h3&gt;
&lt;p&gt;In ROS, the fundamental building blocks are called nodes. Each node is responsible for specific tasks, such as controlling devices and sensors or executing computational algorithms. Ideally, each node handles a separate task, whether it's for low-level processes like hardware control or high-level processes like decision-making algorithms. Nodes communicate with each other through topics or services, enabling a modular and distributed architecture.&lt;/p&gt;
&lt;p&gt;There are two primary types of nodes: publishers and subscribers. As the names suggest, publishers are responsible for sending messages to topics, while subscribers receive messages from these topics by subscribing to them. This structure allows ROS to efficiently manage and distribute software across different nodes.&lt;/p&gt;
&lt;h3&gt;Topics&lt;/h3&gt;
&lt;p&gt;Inter-node communication in ROS is facilitated through topics. A topic is a communication channel that describes a data stream used to exchange information between different nodes. Topics are used to send streams of messages of a single type, such as sensor data or camera images. Nodes can publish messages to topics or subscribe to them to receive messages.&lt;/p&gt;
&lt;p&gt;The number of nodes that can publish to or subscribe to a topic is generally limited by system resources, particularly RAM. Each topic has a unique name and a defined message type, ensuring that the correct data is routed to the appropriate nodes. In ROS 1, the relationship between nodes and topics is managed by the ROS master, while in ROS 2, this role is handled by the Data Distribution Service (DDS), a management middleware.&lt;/p&gt;
&lt;h3&gt;Services&lt;/h3&gt;
&lt;p&gt;Services in ROS provide an alternative communication method between nodes, resembling the server-client architecture model, similar to a remote procedure call (RPC). In this setup, a client node sends a request, and a server node responds to that request. This establishes a bidirectional communication channel between the client and server nodes. However, unlike topics, which allow continuous data streaming, services are designed for one-time communication and are typically used to invoke specific actions.&lt;/p&gt;
&lt;h3&gt;Actions&lt;/h3&gt;
&lt;p&gt;For tasks that require time-extended operations, ROS introduces the concept of actions. Actions are designed to handle more complex tasks that go beyond the immediate request-response model of services. A ROS action is defined by three key messages: goal, result, and feedback.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Goal&lt;/strong&gt;: This message represents the desired state or objective that the action aims to achieve.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Result&lt;/strong&gt;: This message provides the actual output or outcome after the action has been completed.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Feedback&lt;/strong&gt;: This message is sent periodically during the execution of the action to track and report the progress of the task.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Parameters&lt;/h3&gt;
&lt;p&gt;In ROS, the robot's environment and runtime variables are stored on the ROS parameter server. These parameters are organized as key-value pairs, similar to dictionary data structures. Since the parameter server is not optimized for high-performance operations, it is best suited for managing configuration parameters, such as static, and non-binary data.&lt;/p&gt;
&lt;h3&gt;ROS Package&lt;/h3&gt;
&lt;p&gt;A ROS package is typically developed to perform a specific task, such as control or navigation. A package can contain one or multiple nodes, and it may also include related messages and services. Each package is designed to encapsulate all the necessary components to accomplish its designated task.&lt;/p&gt;
&lt;h2&gt;ROS vs ROS 2&lt;/h2&gt;
&lt;p&gt;In recent years, intensive efforts have been made within the Open Source Robotics Foundation's (OSRF) ROS community to enhance the durability and real-time sensitivity of ROS. These efforts are now bearing fruit, leading to the release of a new generation of ROS, known as ROS 2.&lt;/p&gt;
&lt;p&gt;The primary difference between ROS 2 and its predecessor, ROS, lies in the underlying communication architecture. In ROS 2, the publisher/subscriber communication model has shifted from the TCP/UDP multicast-based ROS master to the Data Distribution Service (DDS). DDS provides powerful features that significantly strengthen ROS 2's capabilities, making it more suitable for designing production-grade, real-time robotic systems.&lt;/p&gt;
&lt;p&gt;Moreover, ROS 2 offers broader compatibility with operating systems, including Windows, macOS, and Real-Time Operating Systems (RTOS), expanding its usability across different platforms.&lt;/p&gt;
&lt;p&gt;&lt;img alt="ROS vs ROS 2 component stack" src="https://cdn-images-1.medium.com/max/800/1*S2Aeb4GlN-Y7QKMcU1t5Bg.png" /&gt;&lt;/p&gt;
&lt;h2&gt;ROS Computation Graph&lt;/h2&gt;
&lt;p&gt;Let's consider designing a robot that follows a particular object using its onboard sensors. The system we need to build involves several components:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Camera Device: To capture images of the object, the robot requires a camera.&lt;/li&gt;
&lt;li&gt;Perception System: This system processes the camera images to determine the object's location. It analyzes the visual data to extract relevant information about the object's position.&lt;/li&gt;
&lt;li&gt;Control System: Based on the information from the perception system, the control system makes decisions about the direction in which the robot should move. It translates the object's location into movement commands.&lt;/li&gt;
&lt;li&gt;Motors: To execute these commands, the robot uses motors that drive the wheels and allow the robot to move toward the object.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Using ROS, we might construct this system as follows:&lt;/p&gt;
&lt;p&gt;&lt;img alt="Example computation graph" src="https://cdn-images-1.medium.com/max/800/1*PnKf4vFYdGXq8h0VDFr-cQ.png" /&gt;&lt;/p&gt;
&lt;p&gt;Each subsystem in our robot design can be represented as a ROS node. Therefore, we will have four distinct nodes, each handling a specific executable function:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Camera Driver Node: This node is responsible for fetching raw images from the camera device and publishing these images to the relevant topic.&lt;/li&gt;
&lt;li&gt;Object Detector Node: This node subscribes to the topic where raw images are published. It processes these frames to extract useful information about the object being followed, such as its location. The node then publishes this information to another topic with an appropriate message type.&lt;/li&gt;
&lt;li&gt;Target Follower Node: Based on the object location data received from the object detector node, this node calculates the commands required to steer the robot toward the object. It subscribes to the object location topic, processes the information, and publishes movement commands to a separate topic.&lt;/li&gt;
&lt;li&gt;Motor Driver Node: This low-level control node receives movement commands from the target follower node and uses them to control the motors, thereby steering the robot's wheels.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;This concludes the discussion on ROS Conceptual Design Patterns, which is the first article in our robotics series. In my next posts, I plan to delve into the ROS file system and the ROS navigation stack. Stay tuned!&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;[1] &lt;a href="http://wiki.ros.org/"&gt;http://wiki.ros.org/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href="https://index.ros.org/doc/ros2/"&gt;https://index.ros.org/doc/ros2/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[3] &lt;a href="http://wiki.ros.org/gazebo"&gt;http://wiki.ros.org/gazebo&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[4] Quigley, Morgan, et al. “ROS: an open-source Robot Operating System.” ICRA workshop on open source software. Vol. 3. №3.2. 2009.&lt;/p&gt;</description><pubDate>Thu, 27 Jan 2022 12:00:00 GMT</pubDate></item><item><title>Linux Process Isolation and Docker Containers</title><link>https://www.erdo.dev/blog/2021-09-12_Linux-Process-Isolation-and-Docker-Containers/</link><description>&lt;h1&gt;Linux Process Isolation and Docker Containers&lt;/h1&gt;
&lt;p&gt;12 Sep 2021&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/1*ekWrA5PWqYMHgc_82A5BNQ.png" /&gt;&lt;/p&gt;
&lt;p&gt;In today's rapidly evolving technological landscape, managing software environments and ensuring consistency across various systems are paramount. This need has led to the widespread adoption of containerization - a method that provides a lightweight, efficient solution for isolating applications and their dependencies. Containers have become a cornerstone of modern software development and deployment, offering significant advantages over traditional virtual machines.&lt;/p&gt;
&lt;p&gt;This article delves into the fundamentals of Linux process isolation and how Docker containers leverage this concept. We will explore the key techniques that enable process isolation, such as &lt;code&gt;chroot&lt;/code&gt;, namespaces, and cgroups, and compare them with virtual machines to understand the distinct advantages of containers. Additionally, we will cover practical aspects of Docker, from installation to managing containers, illustrating how it simplifies application deployment and enhances development workflows. By understanding these concepts, we can appreciate why containers are a preferred choice for many developers and organizations today.&lt;/p&gt;
&lt;h1&gt;Containers&lt;/h1&gt;
&lt;p&gt;Containers are an abstraction at the app layer that packages code and dependencies together. Multiple containers can run on the same machine and share the OS kernel with other containers, each running as isolated processes in user space. In the end, the container is a process that runs on the OS kernel but with a little extra isolation.&lt;/p&gt;
&lt;h1&gt;Virtual Machines&lt;/h1&gt;
&lt;p&gt;Virtual machines (VMs) are an abstraction of physical hardware turning one server into many servers, the hypervisor allows multiple VMs to run on a single machine. Each VM includes a full copy of an operating system, the application, necessary binaries, and libraries - taking up tens of GBs. VMs can also be slow to boot.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Virtual Machine vs container. The figure is taken from https://k21academy.com/docker-kubernetes/docker-vs-virtual-machine/" src="https://cdn-images-1.medium.com/max/800/0*VgBN-MJj_eXYjEtY.png" /&gt;&lt;/p&gt;
&lt;h2&gt;Why Containers?&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Isolation: Containers are independent of the OS behind the container.&lt;/li&gt;
&lt;li&gt;Repeatability: Containers will run the same in another machine since everything your app needs is packaged within the container.&lt;/li&gt;
&lt;li&gt;Security: A container can not access either processes or containers on the OS, each one has an individual process namespace.&lt;/li&gt;
&lt;li&gt;Clean setup/remove: Set up or remove the whole app and its dependencies with only one command.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Advantages of Containers&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;Run in seconds instead of minutes.&lt;/li&gt;
&lt;li&gt;Consuming fewer resources results in less disk space.&lt;/li&gt;
&lt;li&gt;Uses less memory.&lt;/li&gt;
&lt;li&gt;Does not need a full OS.&lt;/li&gt;
&lt;li&gt;Provide faster deployment.&lt;/li&gt;
&lt;li&gt;Quick testing.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;How do Containers work?&lt;/h2&gt;
&lt;p&gt;There is no such concept as the container in Linux. We can verify this by grepping the source code of Linux. But then how do these containers work? We as developers, use interfaces called container runtimes such as Docker to create what we call containers in a more user-friendly way. These container runtimes are just programs that make system calls to the OS kernel. Therefore Docker is a program that makes system calls to the Linux kernel for creating containers easily as we desire. Docker is not the main thing behind the containers, it is just an interface that presents our containers in a language that we can understand. So how the containers are implemented in the Linux kernel?&lt;/p&gt;
&lt;h3&gt;1. Isolation&lt;/h3&gt;
&lt;p&gt;Restricting what the process sees.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;chroot:&lt;/strong&gt; The chroot is an operation on Unix-based operating systems that changes the current root directory, as its name refers to it (change root), for the selected running process and children of that process. It is the oldest restriction/isolation operation in Unix-based operating systems among the other utility operations. It basically creates an illusionistic root directory that isolates the specific command i.e. process from the other processes. This illusionistic fake root directory is often called &lt;em&gt;chroot jail&lt;/em&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;unshare:&lt;/strong&gt; The unshare is an operation that has been a part of the Linux kernel since 2002 that helps us create namespaces. Just like the chroot operation, the unshare operation also provides isolation between processes. There are different types of namespaces as follows:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;User Namespace&lt;/li&gt;
&lt;li&gt;Process ID (PID) Namespace&lt;/li&gt;
&lt;li&gt;Network Namespace&lt;/li&gt;
&lt;li&gt;Mount Namespace&lt;/li&gt;
&lt;li&gt;Interprocess Communication (IPC) Namespace&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Each namespace type has its unique properties that differ from others.&lt;/p&gt;
&lt;h3&gt;2. Resource Controls&lt;/h3&gt;
&lt;p&gt;Restricting the resources used by the process.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;cgroups:&lt;/strong&gt; The cgroups, also known as change groups, is a Linux kernel operation that allows the creation of a hierarchy for a selected set of processes. The key feature of the cgroups operation that distinguishes it from the others is hierarchical management and allocation of system resources like CPU, memory, and storage for the selected process instances of the groups.&lt;/p&gt;
&lt;h1&gt;What is Docker?&lt;/h1&gt;
&lt;ul&gt;
&lt;li&gt;Docker is a tool for running applications in an isolated environment.&lt;/li&gt;
&lt;li&gt;It is similar to a virtual machine.&lt;/li&gt;
&lt;li&gt;The app runs in the same environment regardless of which machine it is since it is isolated.&lt;/li&gt;
&lt;li&gt;The app works on any machine regardless of which OS it uses, what type of hardware is equipped with etc.&lt;/li&gt;
&lt;li&gt;Docker is a standard for software deployment nowadays.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="Docker workflow. The figure is taken from https://www.researchgate.net/profile/Yahya-Al-Dhuraibi/publication/308050257/figure/fig1/AS:433709594746881@1480415833510/High-level-overview-of-Docker-architecture.png" src="https://cdn-images-1.medium.com/max/800/1*pebo5ZC35HDY6osrty5F8A.png" /&gt;&lt;/p&gt;
&lt;h2&gt;Install Docker&lt;/h2&gt;
&lt;p&gt;Since there are a bunch of sources about this on the internet, I will not cover it in this article. I recommend you follow the official &lt;a href="https://docs.docker.com/get-docker/"&gt;Docker page&lt;/a&gt; for the installation.&lt;/p&gt;
&lt;h2&gt;Docker Image&lt;/h2&gt;
&lt;p&gt;Image is a template for creating an environment of your choice (DB, web app, or others). It is a snapshot of your application that has everything needed to run it.&lt;/p&gt;
&lt;h2&gt;Container&lt;/h2&gt;
&lt;p&gt;Running instances of images called containers.&lt;/p&gt;
&lt;h2&gt;Pulling an Image&lt;/h2&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;docker pull nginx  
docker images  # list the images on your machine  
docker image ls  # list the images on your machine
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Running a Container&lt;/h2&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;docker run nginx:latest  # run the container  
docker run — name given\_name nginx:latest  #give a name to container  
docker container ls or docker ps  # list the running containers
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Exposing Ports&lt;/h2&gt;
&lt;p&gt;Since containers work in an isolated environment, most of the time, you might want to expose some ports in order to view or interact with your applications.&lt;/p&gt;
&lt;p&gt;&lt;code&gt;-p&lt;/code&gt; flag manages the port relations of your Docker container. For example, the following command line exposes port 80 of the Docker container and maps it to localhost’s 8080 port:&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;docker run -d -p 8080:80 nginx:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can also expose multiple ports for a single Docker container using more than one &lt;code&gt;-p&lt;/code&gt; flag. See the following command line:&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;docker run -d -p 3000:80 -p 8080:80 nginx:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Managing Containers&lt;/h2&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;docker ps  # list the running container  
docker ps -a  # list all containers  
docker ps -q  # list the containers with only numeric ids  
docker stop container\_id  # stops the container with indicated id  
docker start container\_id  # starts the container with indicated id  
docker rm container\_id  # delete the container with indicated id
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Volumes&lt;/h2&gt;
&lt;p&gt;Volumes are the utility functions for Docker containers that allow sharing of data, files &amp;amp; folders, between host and container or between containers.&lt;/p&gt;
&lt;h3&gt;Volumes Between Host and Container&lt;/h3&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;docker -run — name cwebsite -v /Users/user/Desktop/website:/usr/share/nginx/html:ro -d -p 8080:80 nginx:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;ro:&lt;/strong&gt; read-only (container only allowed to read files and folders)&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;wo:&lt;/strong&gt; write-only (container only allowed to write files and folders)&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;If you don't specify it will allow both writing and reading. If we create a folder or a file in the host that will appear in the container as well.&lt;/p&gt;
&lt;h3&gt;Volumes Between Containers&lt;/h3&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;docker run --name website-copy --volumes-from website -d -p 8081:80 nginx:latest
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Docker Specific Files&lt;/h2&gt;
&lt;p&gt;&lt;strong&gt;Dockerfile:&lt;/strong&gt; A Dockerfile is a kind of manifest that describes what should that docker image contain, and how it should be constructed.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Allow us to build our images.&lt;/li&gt;
&lt;li&gt;Series of steps that define your Docker image.&lt;/li&gt;
&lt;li&gt;Dockerfile keywords: FROM, WORKDIR, ADD, RUN, CMD, etc.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;To create an image with a Dockerfile we simply run this command:&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;docker build -t tag:version path\_of\_dockerfile
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;.dockerignore:&lt;/strong&gt; You have designed an app and coded it with your favorite programming language. Now you want to deploy it using Docker containerization technology. At the same time, you pushed your project to GitHub, thus your project folder contains some .git folders that are required for the GitHub repository. These types of folders or files are unnecessary for the deployment process. That’s why we do not want to include them in our Docker image. For this sake, we simply add the names of folders and files that we do not want to include in our Docker image to the .dockerignore file.&lt;/p&gt;
&lt;h2&gt;Build an Image for Your Python App&lt;/h2&gt;
&lt;p&gt;Let’s say you want to have a web app written with Python programming language using the Flask framework.&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;cd /path/to/python-docker
pip3 install Flask
pip3 freeze &amp;gt; requirements.txt$ touch app.py
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;After following the steps above, you have created a Python file and you are ready to write your code. In this article, for the sake of simplicity, we are going to write a few lines of code that make a simple web request, a Hello World web app. Now you can open your project file with your favorite IDE or text editor selection like VSCode or Sublime, etc., and put the code below inside the file.&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;from flask import Flask
app = Flask(__name__)

@app.route('/')
def hello_world():
    return 'Hello, Docker!'
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You have tested the app by typing the run command &lt;code&gt;python3 -m flask run&lt;/code&gt; . When you run this command it lists that the app is running on your local machine with a port number 5000. You tested and confirmed that the app is working properly as you desired by opening a new browser and navigating to &lt;a href="http://localhost:5000"&gt;http://localhost:5000&lt;/a&gt;.&lt;/p&gt;
&lt;p&gt;Now you want to launch and serve this web app to users around the world. The traditional way of doing this is serving your app on a server like Amazon, Google, etc. Using this way is working, but it is not efficient because when you need updates or bug fixes you need to connect to the server for example via SSH and do what you need just like on your local machine which causes interruption on your served app.&lt;/p&gt;
&lt;p&gt;Therefore you decided to deploy your app using much more modern technology i.e. Docker. Of course, there are more advanced ways of deploying apps using different stacks of technologies like Docker + Kubernetes + Jenkins CI/CD tools, etc. but these are not within the scope of this article and will not be covered here. Now your deployment technology is Docker and for deploying your web app using Docker, you will eventually need a Dockerfile which we discussed in earlier titles.&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;FROM python:3.8-slim-buster
WORKDIR /app
COPY requirements.txt requirements.txt
RUN pip3 install -r requirements.txt
COPY . .
CMD [ &amp;quot;python3&amp;quot;, &amp;quot;-m&amp;quot; , &amp;quot;flask&amp;quot;, &amp;quot;run&amp;quot;, &amp;quot;--host=0.0.0.0&amp;quot;]
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;You can now build your web app’s Docker image using the Dockerfile above and by typing the command &lt;code&gt;docker build -t python-docket:v0&lt;/code&gt; . Afterward, you achieve a Docker image that wraps your web app and it is ready to deploy.&lt;/p&gt;
&lt;p&gt;Thank you for reading this article, and I will see you in the next one!&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;[1] &lt;a href="https://man7.org/linux/man-pages/man2/chroot.2.html"&gt;https://man7.org/linux/man-pages/man2/chroot.2.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href="https://www.ibm.com/docs/en/zos/2.2.0?topic=descriptions-chroot-change-root-directory-execution-command"&gt;https://www.ibm.com/docs/en/zos/2.2.0?topic=descriptions-chroot-change-root-directory-execution-command&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[3] &lt;a href="https://man7.org/linux/man-pages/man1/unshare.1.html"&gt;https://man7.org/linux/man-pages/man1/unshare.1.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[4] &lt;a href="https://www.nginx.com/blog/what-are-namespaces-cgroups-how-do-they-work/"&gt;https://www.nginx.com/blog/what-are-namespaces-cgroups-how-do-they-work/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[5] &lt;a href="https://man7.org/linux/man-pages/man7/cgroups.7.html"&gt;https://man7.org/linux/man-pages/man7/cgroups.7.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[6] &lt;a href="https://www.ibm.com/docs/en/spectrum-symphony/7.3.0?topic=limits-control-groups-cgroups-limiting-resource-usage-linux"&gt;https://www.ibm.com/docs/en/spectrum-symphony/7.3.0?topic=limits-control-groups-cgroups-limiting-resource-usage-linux&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[7] &lt;a href="https://docs.docker.com/get-started/overview/"&gt;https://docs.docker.com/get-started/overview/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[8] &lt;a href="https://docs.docker.com/engine/reference/builder/"&gt;https://docs.docker.com/engine/reference/builder/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[9] &lt;a href="https://docs.docker.com/language/python/build-images/"&gt;https://docs.docker.com/language/python/build-images/&lt;/a&gt;&lt;/p&gt;</description><pubDate>Sun, 12 Sep 2021 12:00:00 GMT</pubDate></item><item><title>What Are Real Time Systems and Real Time Operating Systems?</title><link>https://www.erdo.dev/blog/2021-08-15_What-Are-Real-Time-Systems-and-Real-Time-Operating-Systems?/</link><description>&lt;h1&gt;What Are Real Time Systems and Real Time Operating Systems?&lt;/h1&gt;
&lt;p&gt;15 Aug 2021&lt;/p&gt;
&lt;p&gt;&lt;img alt="The figure is taken from https://www.wallpaperbetter.com/de/hd-wallpaper-fuhzp" src="https://cdn-images-1.medium.com/max/800/1*wc2mgaPW9wianNSrXf951Q.jpeg" /&gt;&lt;/p&gt;
&lt;p&gt;Hello, everyone. In this article, I will talk about what is a real-time, real-time system, and real-time operating system means. This article will be relatively different from the others and I will be explaining the meanings of a few terms. I think it is a big plus for us to be developing our technical thesaurus because; even if we do not use these terms directly, someday if we are involved in a project that uses some of these terms, and if we encounter a problem when the day comes, we can easily find out which term it originated from and find the relevant solution by researching this term. In summary, when we have a wide technical term treasury, it saves us time and speed in our projects and makes it easier for us to detect errors. Now let’s move on to our main topic.&lt;/p&gt;
&lt;h2&gt;What is a Real-Time System?&lt;/h2&gt;
&lt;p&gt;In fact, we can summarize it as follows; the systems that produce an output in a certain time to the inputs from outside are called real-time systems. For example; unmanned aerial vehicles react in a very short time to the commands we give from the radio controller. Therefore, unmanned aerial vehicles are real-time systems, in the same way, the airbags in our cars are real systems since they produce instantaneous responses to the given input. Examples of non-real-time systems would be computers or washing machines. Because in these systems, there is no concern about producing instant output to the given input. It is an important distinction in terms of design that the system we will design is real-time or not real-time because there are differences between designing real-time systems and designing non-real-time systems.&lt;/p&gt;
&lt;p&gt;There are two types of real-time systems;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Hard Real-Time:&lt;/strong&gt; The degree of tolerance of a possible delay in the completion of the tasks to be performed by the system is very low (zero or a manufacturer-defined threshold). Tasks that cannot be completed on time are critical to the system and have devastating effects.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Soft Real-Time:&lt;/strong&gt; The completion time of the tasks to be performed by the system is not as critical as in hard real-time or the system can tolerate it during the latency period.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Response time does not determine whether a system is hard or soft in real time. The criterion that determines this is what happens if the system does not respond. For example, a video game that we play at 60 FPS will draw the graphics in 1/60th of a second after our commands, but if the drawing process is delayed for any reason, this will not have a devastating effect. Of course, it will affect the efficiency of playing the game, but it is not a critical problem, it can be ignored depending on the situation. But if we are talking about a competitive esports game, the consequences of delays in the game can be seen as devastating, so we can also assume it is as a hard real-time system. Unlike video games, if surgical robots or airbag systems respond later than the threshold response time set by the manufacturer, it can cause that patient or driver injury or even death, so such situations are very critical.&lt;/p&gt;
&lt;p&gt;Below are examples of hard real-time and soft real-time.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Hard Real-Time:&lt;/strong&gt; A medical robot, a surgical robot. If it cannot respond to the inputs given by the doctor within the specified time (milliseconds, microseconds), it is very inefficient, and devastating results may occur. The response time must be under a certain limit.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Soft Real-Time:&lt;/strong&gt; In a video game, when we give input from the keyboard to give the jump command to the character, the jump animation graphics drawn on the screen, based on 30 FPS, should be drawn on the screen in 1/30th of a second after the command we give, which is soft real-time.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Throughput vs Latency&lt;/h3&gt;
&lt;p&gt;It is very important to understand these two terms. In a team discussion or product demonstration, we need to understand what is meant when the statement “We made concessions from delay to increase the transfer speed”. Now let’s try to understand these two terms.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Latency:&lt;/strong&gt; The time it takes for a package to be transported to its destination.&lt;/p&gt;
&lt;p&gt;For example, if we consider the package as a physical product on the conveyor belt, the time taken for the package to complete its operations on the conveyor belt and exit the belt is equivalent to a delay. Or, when we click to open a new page on a website, the time it takes for the data packet of the page to be opened from the server to the client is called latency.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Throughput:&lt;/strong&gt; The number of packets sent and received per unit time.&lt;/p&gt;
&lt;p&gt;If we continue with the conveyor belt example, the number of packages that will leave the conveyor belt at one time, let’s say one minute, after the first package reaches the destination, gives the transfer rate. Likewise, the total amount of packets that a web server sends to the client in one minute is also called the transfer rate.&lt;/p&gt;
&lt;p&gt;Below is a visualization of the terms latency and throughput in the web server-client example.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Latency vs throughput. The figure is taken from https://www.comparitech.com/net-admin/latency-vs-throughput/" src="https://cdn-images-1.medium.com/max/800/0*R7LoaJr0M-l0jILV.jpeg" /&gt;&lt;/p&gt;
&lt;h3&gt;OS and RTOS&lt;/h3&gt;
&lt;h3&gt;What is an Operating System (OS)?&lt;/h3&gt;
&lt;p&gt;An operating system is a computer program that supports the basic functions of the computer and serves other programs and applications running on the computer. Applications provide the functionality that the computer user wants or needs, while the services provided by the operating system make the execution of applications faster, simpler, and easier. For example, if you are reading a web page, you are using a web browser, which can be thought of as an application program that provides the functionality you are interested in, and that will run in an operating system-provided environment.&lt;/p&gt;
&lt;h2&gt;What is a Real-Time Operating System (RTOS)?&lt;/h2&gt;
&lt;p&gt;Most operating systems seem to allow multiple programs to run simultaneously. This is called multitasking. In reality, each processor core can only run a single program, thread, or task thread at any one time. The component called the task scheduler, which is part of the operating system, is responsible for deciding which program to run when and quickly switches between each program, giving the user the illusion of simultaneous execution.&lt;/p&gt;
&lt;p&gt;The type of operating system is determined by the way the task scheduler decides in what order to run the programs to be executed. For example, in a multi-user operating system, like Unix, the scheduler used ensures that each user gets a fair amount of processing time. For another example, on a desktop operating system, like Windows, the task scheduler tries to keep the computer responsive to its user.&lt;/p&gt;
&lt;p&gt;The programmer in a real-time operating system (RTOS) is designed to provide a predictable (deterministic) execution pattern. This is especially important for embedded systems because embedded systems often have real-time requirements. Real-time requirements are requirements that specify that the embedded system must respond to a specific event within a certain threshold time. A guarantee of fulfilling real-time requirements can only be made if the behavior of the operating system’s scheduler is predictable, that is, deterministic. Some of the most widely used RTOS are LynxOS, OSE, QNX, RTLinux, VxWorks, Windows CE, eCos, and FreeRTOS.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Deterministic System:&lt;/strong&gt; In mathematics and physics, it is defined as systems that do not have randomness in the development of their future states. Therefore a deterministic system always produces the same output from a given initial condition or initial state.&lt;/p&gt;
&lt;h3&gt;Classification of RTOS&lt;/h3&gt;
&lt;p&gt;RTOS can be divided into three types:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Hard RTOS:&lt;/strong&gt; The degree of tolerance of the delay in the completion of tasks is quite small (zero or close to zero). Tasks not done on time have a devastating effect on the system.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Firm RTOS:&lt;/strong&gt; Delays in the completion of tasks are unacceptable, but tasks that cannot be completed on time do not have a devastating effect on the system, they may cause a quality reduction.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Soft RTOS:&lt;/strong&gt; Delays in the completion of tasks may not be significant and losses in this time can be tolerated. Decreases in system quality due to delays are acceptable.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;What is a Task Scheduler?&lt;/h3&gt;
&lt;p&gt;Task Scheduler keeps status logs of each task and selects the task that is ready to be executed, then allocates the processor to that task. The task scheduler ensures the most efficient use of the CPU in multi-tasking programs. Thus, it reduces the waiting time. There are generally two types of task schedulers.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;strong&gt;Non-Preemptive Scheduling:&lt;/strong&gt; There is no priority order between tasks and all tasks are considered with the same priority. When a task begins to be executed, another task begins to be executed upon the completion of this task.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Preemptive Scheduling:&lt;/strong&gt; Always the processor checks for high-priority tasks. If a high-priority task is ready to be processed, the task on the processor is immediately suspended and control of the processor is given to the higher-priority task.&lt;/li&gt;
&lt;li&gt;&lt;strong&gt;Dispatcher:&lt;/strong&gt; It is used to give control of the processor to the task selected by the task scheduler. In this way, the execution flow is changed. Anytime an RTOS is running, its execution flow passes through the task program code, and interrupts the service routine (ISR), or kernel.&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;[1] Fan, Xiaocong. Real-Time Embedded Systems: Design Principles and Engineering Practices. Newnes, 2015.&lt;/p&gt;
&lt;p&gt;[2] Jane Liu. Real-Time Systems. Integre Technical Publishing Co., Inc., 2000.&lt;/p&gt;</description><pubDate>Sun, 15 Aug 2021 12:00:00 GMT</pubDate></item><item><title>Music Generation with LSTM Based RNN</title><link>https://www.erdo.dev/blog/2021-04-03_Music-Generation-with-LSTM-Based-RNN/</link><description>&lt;h1&gt;Music Generation with LSTM Based RNN&lt;/h1&gt;
&lt;p&gt;03 Apr 2021&lt;/p&gt;
&lt;p&gt;Hello everyone. In this article, I will try to explain what I know about music generation with LSTM (long short-term memory) based RNN (recursive neural networks). Let's first examine what kind of information contains the dataset I have used in the training phase of the model.&lt;/p&gt;
&lt;h2&gt;About the Dataset&lt;/h2&gt;
&lt;p&gt;As we all know, music is represented by notes. I preferred to use an alternative note system in the dataset, known as the ABC notation, instead of the classical notes in the style of Do, Re, Mi, etc. In ABC notation, numbers, and special characters are used along with letter notations from A to G to represent the given notes. Each letter corresponds to classical notes such as Do, Re, and Mi in classical notes. In addition to the notes that make up the melody, other units are used as additional information; reference number, composer, origin, note length, tempo, rhythm key, ornament, etc. Each of these values ​​constitutes the features of our data set. The ABC notation is often used to represent traditional folk music. The dataset I have used is compiled from &lt;a href="https://cobb.ece.wisc.edu/irish/Tunebook.html"&gt;Cobb’s Irish Folk Music&lt;/a&gt; [1]. Below you will see sample music expressed with ABC notation from the dataset.&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;X:1   
T:Alexander's   
Z: id:dc-hornpipe-1   
M:C|   
L:1/8   
K:D Major  
(3ABc|dAFA DFAd|fdcd FAdf|gfge fefd|(3efe (3dcB A2 (3ABc|! dAFA DFAd|fdcd FAdf|gfge fefd|(3efe dc d2:| ! AG|FAdA FAdA|GBdB GBdB|Acec Acec|dfaf gecA|! FAdA FAdA|GBdB GBdB|Aceg fefd|(3efe dc d2:|!
&lt;/code&gt;&lt;/pre&gt;

&lt;h2&gt;Implementation&lt;/h2&gt;
&lt;p&gt;Here, we are facing a problem: Can our computers make sense of data that contains letters and special characters? Since we are going to multiply the features by the weight values, B x 0.23 would be an illogical operation, it seems unlikely, doesn't it? For this reason, we must bring the data into a format that the computer can understand. Just as computers represent images as matrices containing pixel values, we will assign a numerical value to each note in the data set, whether it is a letter or a special character. This operation is known as encoding in the literature.&lt;/p&gt;
&lt;p&gt;To perform the encoding process, we first collect all the songs in a single list with the help of the code snippet below. After extracting each original character in this list and sorting it from small to large, we throw it into the &lt;code&gt;vocab&lt;/code&gt; variable. The &lt;code&gt;vocab&lt;/code&gt; variable contains unique characters that carry information and represent our songs. Then we define the operations that allow us to assign numerical values to these unique characters, that is, to perform the encoding process: &lt;code&gt;char2id&lt;/code&gt;, which maps characters to numbers, and, &lt;code&gt;idx2char&lt;/code&gt; which maps numbers to characters.&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;# Join our list of song strings into a single string containing all songs
songs_joined = &amp;quot;\n\n&amp;quot;.join(songs) 
# Find and then sort all unique characters in the joined string
vocab = sorted(set(songs_joined))
print(&amp;quot;There are&amp;quot;, len(vocab), &amp;quot;unique characters in the dataset&amp;quot;)

# Define numerical representation of text data so that can be process by computer

# Create a mapping from character to unique index.
# For example, to get the index of the character &amp;quot;d&amp;quot;, 
# we can evaluate `char2idx[&amp;quot;d&amp;quot;]`.  
char2idx = {char:id for id, char in enumerate(vocab)}

# Create a mapping from indices to characters. This is
# the inverse of char2idx and allows us to convert back
# from unique index to the character in our vocabulary.
idx2char = np.array(vocab)

print('{')
for char,_ in zip(char2idx, range(20)):
print('  {:4s}: {:3d},'.format(repr(char), char2idx[char]))
print('  ...\n}')
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Below you can see each unique character in the dataset and their corresponding numerical value.&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;{     
   '\\n':   0,  
   ' ' :   1,  
   '!' :   2,  
   '&amp;quot;' :   3,  
   '#' :   4,  
   &amp;quot;'&amp;quot; :   5,  
   '(' :   6,  
   ')' :   7,  
   ',' :   8,  
   '-' :   9,  
   '.' :  10,  
   '/' :  11,  
   '0' :  12,  
   '1' :  13,  
   '2' :  14,  
   '3' :  15,  
   '4' :  16,  
   '5' :  17,  
   '6' :  18,  
   '7' :  19,  
   ...   
}
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Let’s combine the above-mentioned operations into a function to be more modular and organized.&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;def encode_string(string):
    &amp;quot;&amp;quot;&amp;quot;
    A function to convert all the song strings 
    to a vectorized and numeric representation.

    Args:
    string -- List of strings

    Return:
    encodeded_string -- Encoded list of strings

    NOTE: the output of the `vectorize_string` function 
    should be a np.array with `N` elements, where `N` is
    the number of characters in the input string
    &amp;quot;&amp;quot;&amp;quot;

    encodeded_string = np.array([char2idx[char] for char in string])
    return encodeded_string

encodeded_songs = encode_string(songs_joined)

print ('{} &amp;lt;--- characters mapped to int ---&amp;gt; {}'.format(repr(songs_joined[:10]), encodeded_songs[:10]))
# Check that vectorized_songs is a numpy array
assert isinstance(encodeded_songs, np.ndarray), &amp;quot;returned result should be a numpy array&amp;quot;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Following the character encoding process according to the assignments stated before, our sample data including letters, numbers, and special characters transformed like below. In this way, after preprocessing operations performed on our dataset, we now made our dataset ready to use.&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;'X:1\\nT:Alex' &amp;lt;---encoding---&amp;gt; \[49 22 13  0 45 22 26 67 60 79\]`
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Our next step is to break down the text containing the songs into sample batches that we will use during the actual training. Each input string in which we feed our model contains as many characters from the text as the number of &lt;code&gt;seq_length&lt;/code&gt;. Also, to predict the next character, we need to define a target sequence for each input sequence to be used in the training of the model. For each input string, the corresponding target string will contain characters of the same length, except if one character has been shifted to the right.&lt;/p&gt;
&lt;p&gt;To do this, we have to divide the text into &lt;code&gt;seq_length + 1&lt;/code&gt;. Assuming the variable &lt;code&gt;seq_length&lt;/code&gt; is 3 and our text is &lt;em&gt;Helsinki&lt;/em&gt;, our input string will be &lt;em&gt;Hel&lt;/em&gt; and the target string will be &lt;em&gt;els&lt;/em&gt;. The function, whose definition you can see below, allows us to convert this string stream into arrays of the desired size.&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;def get_batch(encodeded_songs, seq_length, batch_size):
    &amp;quot;&amp;quot;&amp;quot;
    Batch definition to create training examples
    &amp;quot;&amp;quot;&amp;quot;

    # The length of the vectorized songs string
    n = encodeded_songs.shape[0] - 1
    # Randomly choose the starting indices for the examples in the training batch
    idx = np.random.choice(n-seq_length, batch_size)

    # A list of input sequences for the training batch
    input_batch = [encodeded_songs[i : i+seq_length] for i in idx]
    # A list of output sequences for the training batch
    output_batch = [encodeded_songs[i+1 : i+seq_length+1] for i in idx]

    # x_batch, y_batch provide the true inputs and targets for network training
    x_batch = np.reshape(input_batch, [batch_size, seq_length])
    y_batch = np.reshape(output_batch, [batch_size, seq_length])

    return x_batch, y_batch

x_batch, y_batch = get_batch(encodeded_songs, seq_length=5, batch_size=1)


for i, (input_idx, target_idx) in enumerate(zip(np.squeeze(x_batch), np.squeeze(y_batch))):
    print(&amp;quot;Step {:3d}&amp;quot;.format(i))
    print(&amp;quot;  input: {} ({:s})&amp;quot;.format(input_idx, repr(idx2char[input_idx])))
    print(&amp;quot;  expected output: {} ({:s})&amp;quot;.format(target_idx, repr(idx2char[target_idx])))
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Sample input series on batch created for trial purposes and expected values:&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;Step   0   input: 18 ('6')   expected output: 0 ('\\n')   
Step   1   input: 0 ('\\n')   expected output: 45 ('T')   
Step   2   input: 45 ('T')   expected output: 22 (':')   
Step   3   input: 22 (':')   expected output: 32 ('G')   
Step   4   input: 32 ('G')   expected output: 73 ('r')
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Now it's time to design our model. We could use classical artificial neural networks (ANNs) in our model, but since the melodies we call music consist of a series of repeating notes, the classical ANNs using the feed-forward technique are somewhat dysfunctional for this problem. The notes that make up our music are not independent of each other, on the contrary, they are arranged one after the other in a way to adapt to the previous one. That is why in our model we will use RNN, which is a more advanced artificial neural network algorithm, that provides a very good solution to such sequence and repetition problems. In addition to classical neural networks, this algorithm can take the output of the previous node as input, while at the same time taking its output as an input for the nodes that are in parallel and after it. Below you can find a diagram where you can see the difference between feed-forward neural networks and RNNs.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Feedforward NN vs Recurrent NN. The figure is taken from https://www.researchgate.net/figure/Feed-forward-and-recurrent-ANN-architecture_fig1_315111480)" src="https://cdn-images-1.medium.com/max/800/0*xu3Kg282H1n2KKwe.png" /&gt;&lt;/p&gt;
&lt;p&gt;Although it offers a great solution for some problems, RNNs have some missing points. One of them is the ability to carry the information of array elements up to a certain past point to the next steps, in other words, their memory is very short and the algorithm starts to be difficult when it comes to using the previous elements. As a solution to this, gate cells have been developed aiming to solve exactly such problems. There are several types of door cells, for example, LSTM and GRU. We will use LSTM of these, and I avoid going into the details of this because it involves some complex mathematical operations and these are not our focus now. But for some intuition, I leave below a visualized LSTM gate cell.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Working principle of an LSTM cell. The figure is taken from https://becominghuman.ai/long-short-term-memory-part-1-3caca9889bbc)" src="https://cdn-images-1.medium.com/max/800/0*k6TQJrYrBARnCjsr.gif" /&gt;&lt;/p&gt;
&lt;p&gt;You can see the summary of our model below.&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;Model: &amp;quot;sequential&amp;quot;
_________________________________________________________________

Layer (type)                 Output Shape              Param #

=================================================================

embedding (Embedding)        (32, None, 256)           21248      
_________________________________________________________________

lstm (LSTM)                  (32, None, 1024)          5246976    
_________________________________________________________________

dense (Dense)                (32, None, 83)            85075

=================================================================

Total params: 5,353,299 Trainable params: 5,353,299 Non-trainable

params: 0
_________________________________________________________________
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;When the training is over, the model presents us with the pieces of music produced by the based RNN model as a string. We copy this sequence and paste it into a notebook that we will open on the computer and save it as &lt;code&gt;.abc&lt;/code&gt; extension. After this process, you can listen to the music track. Remember, the model may not produce a successful result every time, it may be necessary to produce several times to produce a melody with a nice sound. Have a nice try.&lt;/p&gt;
&lt;p&gt;Unique music pieces that emerged at the end of the training:&lt;/p&gt;
&lt;iframe width="100%" height="166" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/824756473&amp;color=ff5500"&gt;&lt;/iframe&gt;
&lt;div style="font-size: 10px; color: #cccccc;line-break: anywhere;word-break: normal;overflow: hidden;white-space: nowrap;text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif;font-weight: 100;"&gt;&lt;a href="https://soundcloud.com/erdem-uysal-578262330" title="R. Erdem Uysal" target="_blank" style="color: #cccccc; text-decoration: none;"&gt;R. Erdem Uysal&lt;/a&gt; · &lt;a href="https://soundcloud.com/erdem-uysal-578262330/ir-sh-folk-by-lstm-based-rnn" title="Irısh Folk By LSTM Based RNN" target="_blank" style="color: #cccccc; text-decoration: none;"&gt;Irısh Folk By LSTM Based RNN&lt;/a&gt;&lt;/div&gt;

&lt;iframe width="100%" height="166" scrolling="no" frameborder="no" allow="autoplay" src="https://w.soundcloud.com/player/?url=https%3A//api.soundcloud.com/tracks/824756467&amp;color=ff5500"&gt;&lt;/iframe&gt;
&lt;div style="font-size: 10px; color: #cccccc;line-break: anywhere;word-break: normal;overflow: hidden;white-space: nowrap;text-overflow: ellipsis; font-family: Interstate,Lucida Grande,Lucida Sans Unicode,Lucida Sans,Garuda,Verdana,Tahoma,sans-serif;font-weight: 100;"&gt;&lt;a href="https://soundcloud.com/erdem-uysal-578262330" title="R. Erdem Uysal" target="_blank" style="color: #cccccc; text-decoration: none;"&gt;R. Erdem Uysal&lt;/a&gt; · &lt;a href="https://soundcloud.com/erdem-uysal-578262330/irish-folk-by-lstm-based-rnn-2" title="Irısh Folk By LSTM Based RNN 2" target="_blank" style="color: #cccccc; text-decoration: none;"&gt;Irısh Folk By LSTM Based RNN 2&lt;/a&gt;&lt;/div&gt;

&lt;p&gt;I did not want to share all the codes here because the article will be too long. However, I shared the dataset and the notebook on &lt;a href="https://github.com/erdemuysalx/ComposerAI"&gt;GitHub&lt;/a&gt; for everyone to experiment. See you in the next article.&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;[1] &lt;a href="https://cobb.ece.wisc.edu/irish/Tunebook.html"&gt;https://cobb.ece.wisc.edu/irish/Tunebook.html&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href="https://machinelearningmastery.com/how-to-prepare-categorical-data-for-deep-learning-in-python/"&gt;https://machinelearningmastery.com/how-to-prepare-categorical-data-for-deep-learning-in-python/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[3] &lt;a href="http://introtodeeplearning.com/"&gt;http://introtodeeplearning.com/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[4] &lt;a href="https://stanford.edu/~shervine/l/tr/teaching/cs-230/cheatsheet-recurrent-neural-networks"&gt;https://stanford.edu/~shervine/l/tr/teaching/cs-230/cheatsheet-recurrent-neural-networks&lt;/a&gt;&lt;/p&gt;</description><pubDate>Sat, 03 Apr 2021 12:00:00 GMT</pubDate></item><item><title>Machine Learning Key Terminology</title><link>https://www.erdo.dev/blog/2020-05-21_Machine-Learning-Key-Terminology/</link><description>&lt;h1&gt;Machine Learning Key Terminology&lt;/h1&gt;
&lt;p&gt;21 May 2020&lt;/p&gt;
&lt;p&gt;Machine Learning domain is very fascinating and it is becoming very powerful and useful technology in today’s world. Even if you are not directly working on machine learning, in somehow you can touch some part of machine learning in any project. Since machine learning is a very wide open space, it is not possible to learn all of the keywords and the theory behind it for those who are not having expertise area on ML. Which is why I am writing this article, to make those people understand or simply give them a insight of simple concepts in machine learning. I explained general aspect of AI, Machine Learning and Deep Learning on my previous article, &lt;a href="https://medium.com/@erdemuysal13/the-rise-of-ai-what-is-ai-d3f796a1c153"&gt;(Introduction to AI, ML, and DL)&lt;/a&gt;. So this will be involved with only Machine Learning. Let’s begin!&lt;/p&gt;
&lt;h3&gt;Key Terminology&lt;/h3&gt;
&lt;p&gt;&lt;strong&gt;Supervised Learning:&lt;/strong&gt; Supervised learning is where you have features and corresponding labels and you use an algorithm to learn the parameters for mapping function from the features to the labels.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Unsupervised Learning:&lt;/strong&gt; Unsupervised learning is where you have features but not corresponding labels.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Semi-Supervised Learning:&lt;/strong&gt; Semi-supervised learning is where you have features with corresponding labels and without labels. Generally, these kinds of models have more unlabeled examples than labeled ones.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Regression:&lt;/strong&gt; A regression model predicts continuous, or numerical values. The numerical value could be the price of a house, the temperature of the weather, etc. Regression models can be grouped under supervised learning. Some of the regression algorithms are Linear and Polynomial Regression, Decision Trees, and Random Forest.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Classification:&lt;/strong&gt; A classification model predicts discrete, or categorical values. The categorical value could be dog or cat, disease or not disease, etc. Classification models can be grouped under supervised learning. Some of the classification algorithms are KNN (K-Nearest Neighbour), Trees, SVM and Logistic Regression.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Clustering:&lt;/strong&gt; A clustering model discovers the inherent groupings in continuous data according to similar features. An example could be the grouping of customers by purchasing behavior. Clustering models can be grouped under unsupervised learning. Some of the Clustering algorithms are K-Means and PCA.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Association:&lt;/strong&gt; An association model discovers rules that describe large partitions of categorical data. An example could be: people that who buy suits also tend to buy ties. Hidden Markov Model and FP-Growth. Association models can be grouped under unsupervised learning.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Models:&lt;/strong&gt; A model defines the mapping relationship between features and labels. The model uses the parameters to make a prediction.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Labels&lt;/strong&gt;: A label is the resultant value or category variable we are predicting (mostly denoted as 'y') as a result of the machine learning model. The label could be the object shown in an image, the future temperature value of weather, or the next word in a text or music lyrics.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Features&lt;/strong&gt;: A feature is an input variable (mostly denoted as 'x') that we use for feeding the machine learning model. The features could be the pixels of an image, past temperature and humidity values of weather, or words in a text or music lyrics.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Examples&lt;/strong&gt;: An example is the set of features and its corresponding label. An example could be the pixels of an image(features) and the object (label) inside this image.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Parameters:&lt;/strong&gt; Parameters are the weights and biases that we are trying to calculate and set their most appropriate values to make a good prediction at the end of the learning process.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Hyper-Parameters:&lt;/strong&gt; Hyper-parameters are the parameters that you are tuning by hand to make the model more predictive. Some of them are learning rate, epoch, batch size, and so on.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Accuracy:&lt;/strong&gt; Accuracy is the one of model metrics that tell us how good our model is at making predictions.&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;[1] &lt;a href="https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/"&gt;https://machinelearningmastery.com/classification-versus-regression-in-machine-learning/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href="https://developers.google.com/machine-learning/crash-course"&gt;https://developers.google.com/machine-learning/crash-course&lt;/a&gt;&lt;/p&gt;</description><pubDate>Thu, 21 May 2020 12:00:00 GMT</pubDate></item><item><title>Why Python Instead of Matlab and R in Machine Learning?</title><link>https://www.erdo.dev/blog/2020-04-22_Why-Python-Instead-of-Matlab-and-R-in-Machine-Learning/</link><description>&lt;h1&gt;Why Python Instead of Matlab and R in Machine Learning?&lt;/h1&gt;
&lt;p&gt;22 Apr 2020&lt;/p&gt;
&lt;p&gt;Machine learning has become an important tool for a vast of scientiﬁc and engineering disciplines and there are a lot of environments and tools to use when applying machine learning solutions, but which one to choose? Python, R, or Matlab? Let’s make a quick comparison between these and discuss the advantages of each one.&lt;/p&gt;
&lt;h2&gt;Why Python?&lt;/h2&gt;
&lt;p&gt;Python is becoming an increasingly central tool for data science. This was not always the case, ten years ago everyone was using Matlab instead of Python. However, due to high prices, licensing issues, and the rapid development of Python, scientiﬁc Python started to gain its user community. Nowadays, Python rapidly becoming the default programming language for practical machine learning applications. Python’s strength is in its simple syntax, readability, variability, and huge community. There are 2 versions: Python 2.7 and 3.6. however, version 2.x will not be supported anymore.&lt;/p&gt;
&lt;h2&gt;Alternatives to Python in Science&lt;/h2&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;| Python vs Matlab| Python vs R |
|  --------  |  -------  |
| January | $250 |
| February | $80 |
| March | $420 |
&lt;/code&gt;&lt;/pre&gt;

&lt;blockquote&gt;
&lt;p&gt;“Matlab is made for mathematicians, R for statisticians and Python for
programmers.”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Essential Modules of Python&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;NumPy: The fundamental package for scientific computing and matrix/numerical analysis&lt;/li&gt;
&lt;li&gt;SciPy: Scientiﬁc computing utilities (linear algebra, FFT, signal/image processing…)&lt;/li&gt;
&lt;li&gt;scikit-learn: Machine learning&lt;/li&gt;
&lt;li&gt;scikit-image: Image processing&lt;/li&gt;
&lt;li&gt;OpenCV: Open Source Computer Vision Library&lt;/li&gt;
&lt;li&gt;Matplotlib: Plotting and visualization&lt;/li&gt;
&lt;li&gt;Seaborn: Statistical data visualization&lt;/li&gt;
&lt;li&gt;Pandas: Data analysis and manipulation&lt;/li&gt;
&lt;li&gt;Tensorﬂow, Keras, PyTorch: Deep Learning&lt;/li&gt;
&lt;li&gt;PyCharm: Editor&lt;/li&gt;
&lt;li&gt;Jupyter Notebook: Notebook format editor&lt;/li&gt;
&lt;li&gt;Spyder: Scientiﬁc Python Development Environment (Comes with Anaconda)&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;Things to Come&lt;/h2&gt;
&lt;ul&gt;
&lt;li&gt;The editor and the environment: Matlab is slightly better than Python&lt;/li&gt;
&lt;li&gt;Linear algebra: Matlab is better than Python&lt;/li&gt;
&lt;li&gt;Programming constructs (loops, classes, etc.): Python better than Matlab&lt;/li&gt;
&lt;li&gt;Machine Learning: Python is a lot better than Matlab&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;[1] &lt;a href="https://sgn-41007-2018.blogspot.com/"&gt;TUT SGN-41007 Pattern Recognition and Machine Learning Course&lt;/a&gt;&lt;/p&gt;</description><pubDate>Wed, 22 Apr 2020 12:00:00 GMT</pubDate></item><item><title>Introduction to AI, ML, and DL</title><link>https://www.erdo.dev/blog/2019-07-07_Introduction-to-AI-ML-and-DL/</link><description>&lt;h1&gt;Introduction to AI, ML, and DL&lt;/h1&gt;
&lt;p&gt;07 Jul 2019&lt;/p&gt;
&lt;p&gt;Lots of people nowadays are all thinking and worried like;&lt;/p&gt;
&lt;blockquote&gt;
&lt;p&gt;“Will a robot take my job in the future? How is artificial intelligence likely to change my job in the near future? Where are AI technologies being used nowadays and where will they come later?”&lt;/p&gt;
&lt;/blockquote&gt;
&lt;p&gt;Before we judge this, let us examine a few simple concepts. But before we start, let me give you a hint, you might think these will be in the future, all are happening right now! As you’ve noticed, artificial intelligence has been a hot topic for several years now. It’s not hard to see if you have an internet connection, because news about it is now everywhere. Some people fear that these developments can be dangerous, and others seem to be greeted with excitement. But it is not a new thing. Since the beginning of the ’50s, some researchers studying this concept. The most important people who play a role in bringing artificial intelligence to the present are computer scientists such as John McCarty and Alan Turing. They started their research based on the “Can machines think?” problem. In 1950, Alan Turing brings up whether machines can think or not, in an article. With his famous Turing Test, it is possible to distinguish whether a machine is intelligent or not. If a person cannot identify a human or a machine behind an interaction, then this means that a machine is an intelligent machine and it can think. However, in 1956, the eponym of artificial intelligence was John McCarthy, who organized an academic conference on the subject. At the end of the conference, the common views of the participants were that the studies on artificial intelligence should be developed to an advanced level. Priority topics included natural language processing, image recognition and classification, and machine learning, which became popular today. However, the real development of these began to be seen lately due to the advancement of hardware technologies and excessive amounts of data.&lt;/p&gt;
&lt;p&gt;While initial research began at university laboratories, it is now becoming an attractive subject for the most prestigious companies. Such as Facebook or NVIDIA even if it is an electronic hardware company. In the last 10 years, artificial intelligence has emerged from a concept used in science fiction films, and books and has become a part of our lives. IBM’s Watson, who won the knowledge contest, and developments such as the Google AI that defeated the world champion in the GO intelligence game today have put artificial intelligence into the agenda of all of us. Today’s largest technology companies invest in artificial intelligence. We are now experiencing more artificial intelligence and even machine learning and deep learning in mobile phones, social media, search engines, and many other places. In the past, while artificial intelligence was the subject of science fiction films and books, today we can see AI impacts everywhere like self-driving cars, content recommendation, object detection, voice assistants, and medical disease diagnostics. It may be wrong to expect to see humanoid robots during this period because research and development are still being done on artificial intelligence, but I don’t think that is too far away.&lt;/p&gt;
&lt;p&gt;Artificial intelligence is a very extensive concept. To understand some things more easily, we can examine AI in three parts and these are:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Artificial Intelligence&lt;/li&gt;
&lt;li&gt;Machine Learning&lt;/li&gt;
&lt;li&gt;Deep Learning&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Also, we will touch on some AI-related fields such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Data Science&lt;/li&gt;
&lt;li&gt;Robotics&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Now let us understand these concepts one by one.&lt;/p&gt;
&lt;h2&gt;Artificial Intelligence&lt;/h2&gt;
&lt;p&gt;Among our concepts, artificial intelligence is the widest scope. We can think of artificial intelligence as a branch of computer science despite it is contradictory. The experts working on artificial intelligence, machine learning, and deep learning have not yet reached a consensus on these words. So far, the scientists involved in this subject have not made a clear definition of artificial intelligence. Because when artificial intelligence is called, many philosophical questions come with it, such as "What is intelligence? Can we call smart, a system that can do what people do? What if they only memorize that specific task?". Although no definite definition can be made, we can simply call artificial intelligence systems that people cannot do or do faster than people.&lt;/p&gt;
&lt;p&gt;&lt;img alt="AI Hierarchy and Algorithms" src="https://cdn-images-1.medium.com/max/800/1*NpcGik_cjRIOESYKOkaefA.png" /&gt;&lt;/p&gt;
&lt;h3&gt;General vs Narrow AI&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;You may see the words "general" and "narrow" AI when reading the news. So what does that mean? Narrow AI is an AI that performs a single job. General AI or Artificial General Intelligence (AGI) refers to a machine capable of performing any intellectual task. All the AI techniques that we use today fall under narrow AI, while general AI stays in the science fiction domain. In reality, despite all the attempts, AI researchers have abandoned the idea of AGI due to the absence of advancement towards it in more than 50 years. Narrow AI, on the other hand, is progressing in leaps and boundaries according to developments on the side of deep learning.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;Strong vs Weak AI&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;Strong AI would be a truly smart and self-conscious “mind.” Weak AI is what we truly have, namely systems that, despite being “merely” computers, display smart behaviors.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;Autonomy&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;The capacity or ability to execute duties without constant user guidance in complex environments.&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h3&gt;Adaptivity&lt;/h3&gt;
&lt;blockquote&gt;
&lt;p&gt;&lt;em&gt;The capacity or ability of learning from experience to enhance efficiency and productivity.&lt;/em&gt;&lt;/p&gt;
&lt;/blockquote&gt;
&lt;h2&gt;Machine Learning&lt;/h2&gt;
&lt;p&gt;Machine learning is the technique of using algorithms to parse data, learn from it, and then make a prediction or determination about something in the world. In doing so, it does not expect you to actively write various codes, but if you feed a machine learning algorithm with data it will start to output to you. The mainstay of machine learning is to create algorithms that can receive various data as input and use statistical analysis for estimation when updating the output as new data emerges.&lt;/p&gt;
&lt;p&gt;Machine learning algorithms are categorized into three groups supervised, unsupervised, and reinforcement learning. Supervised learning consists of classification and regression algorithms that use data that have labels. An example can be orthopedic patients' data that have labels normal and abnormal. Unsupervised learning: It uses data that is unlabeled and uncovers hidden patterns from unlabeled data. An example of this can be another version of orthopedic patients' data that does not have labels. You do not know which orthopedic patient is normal or abnormal. On the other side, the reinforcement learning approach differs from supervised learning and unsupervised learning approaches in machine learning. Reinforcement learning is a machine learning technique that learns what needs to be done for the purpose. In reinforcement learning, our agent reacts to the situations it encounters and receives a numerical reward in return. The agent tries to maximize this reward point it receives. The trial and error method that works in this way is the most distinctive feature of reinforcement learning.&lt;/p&gt;
&lt;h2&gt;Deep Learning&lt;/h2&gt;
&lt;p&gt;Deep Learning is a subfield of machine learning, which itself is a subfield of AI, which itself is a subfield of computer science. Much more data brings out into the open better artificial intelligence functions. Problems will become more complex, as they become more complicated, changeovers will occur from artificial intelligence to machine learning. As it becomes even more complex, transitions from machine learning to deep learning will begin. The more data you have, the better your system work better. While the machine learning process is in one layer, deep learning processes in many layers at the same time. These simultaneous operating layers require advanced processor units. Thanks to today's technologies, GPUs are perfect for this job. GPUs have many more cores than CPUs, which allows them to perform parallel processing. For example, we need to separate a picture of a banana and a picture of an orange. In machine learning, we were trying to introduce the experience that human beings have acquired so far to the machine through the parameters. We had to define many parameters like "If it is orange-colored and round it is probably orange. If it is yellow with the form of a bow, it is probably banana".&lt;/p&gt;
&lt;p&gt;However, deep learning can learn these differences by itself. Only by showing the orange and banana photos to the deep learning system, it can create its own rules, then to reveal the differences, it realizes color and shape are the main distinguishing features of the difference.&lt;/p&gt;
&lt;p&gt;&lt;img alt="Performance of the model vs amount of data. The figure is taken from https://synthesis.ai/2020/03/23/the-data-problem-i-problem-and-plan/" src="https://cdn-images-1.medium.com/max/800/0*WzU-0-GkqBnA20Iq.png" /&gt;&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Why Deep Learning:&lt;/strong&gt; When the amount of data is increased, machine learning techniques are insufficient in terms of performance and deep learning gives a better performance like accuracy.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What is the Amount of Big?:&lt;/strong&gt; It is hard to answer but intuitively 1 million samples are enough to say “big amount of data”.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Usage Fields of Deep Learning:&lt;/strong&gt; Computer vision, natural language processing (NLP), recommendation systems, autonomous driving.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;What is the Difference Between Deep Learning and Machine Learning?:&lt;/strong&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Machine learning covers deep learning.&lt;/li&gt;
&lt;li&gt;Features are given by machine learning manually however deep learning learns features directly from data, without the need for a supervisor.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="Artificial neural network archtiecture" src="https://cdn-images-1.medium.com/max/800/1*3YruJTnSP7d-udgPjnYXIw.png" /&gt;&lt;/p&gt;
&lt;h2&gt;AI-Related Fields&lt;/h2&gt;
&lt;h3&gt;Data Science and Engineering&lt;/h3&gt;
&lt;p&gt;Data science is a fresh term that comprises several sub-disciplines such as machine learning and statistics, a certain domain of computer science including algorithms, data storage, and web. Solutions in data science often require at least a pinch of AI.&lt;/p&gt;
&lt;h3&gt;Robotics&lt;/h3&gt;
&lt;p&gt;Robotics implies building and programming robots to function in complex, real-world situations. In a manner, robotics is AI’s ultimate challenge as it needs a mixture of almost all AI fields such as:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Computer vision, image processing, speech recognition, and natural language processing for environmental understanding and perception,&lt;/li&gt;
&lt;li&gt;Deep reinforcement learning for robot navigation, motion planning, obstacle and collision avoidance,&lt;/li&gt;
&lt;li&gt;Information retrieval, and reasoning under uncertainty for processing instructions and predicting consequences of potential actions,&lt;/li&gt;
&lt;li&gt;Cognitive modeling and affective computing (systems that react to human gestures or mimic emotions) to interact and work with people.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;Machine learning best addresses many of the robotics-related AI issues, making machine learning a key AI branch for robotics.&lt;/p&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;[1] &lt;a href="https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/"&gt;https://blogs.nvidia.com/blog/2016/07/29/whats-difference-artificial-intelligence-machine-learning-deep-learning-ai/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href="https://machinelearningmastery.com/what-is-deep-learning/"&gt;https://machinelearningmastery.com/what-is-deep-learning/&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[3] &lt;a href="https://www.elementsofai.com/"&gt;https://www.elementsofai.com/&lt;/a&gt;&lt;/p&gt;</description><pubDate>Sun, 07 Jul 2019 12:00:00 GMT</pubDate></item><item><title>ARM Architecture Instruction Set</title><link>https://www.erdo.dev/blog/2019-03-06_ARM-Architecture-Instruction-Set/</link><description>&lt;h1&gt;ARM Architecture Instruction Set&lt;/h1&gt;
&lt;p&gt;06 Mar 2019&lt;/p&gt;
&lt;p&gt;In this article, finally, we will start to take a glance at ARM’s arithmetical, logical, data transfer, and branching instructions. But before that, you should check your microprocessor’s model and serial number. Instructions might differ according to these two numbers. The reason for this is that ARM has updated its designs due to technological developments.&lt;/p&gt;
&lt;h2&gt;Instruction Set&lt;/h2&gt;
&lt;p&gt;The arm instructions process data in the register. Therefore, the data must be transferred to the registers before arithmetic, logic, or other types of processing. This information is very important to us. The way to do this is to load data into registers by using load/store instructions. ARM instructions generally take three or two operands. To explain this with an example let’s check the syntax of Instructions:&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;INS Operan1, Operand2, Operand3
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where:
*   INS: Name of the instruction
*   Operand1: Destination register (Operand getting result)
*   Operand2: First register for operation (Operand getting 1st source)
*   Operand3: Second register for operation (Operand getting 2nd source)&lt;/p&gt;
&lt;p&gt;Quick example;&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;ADD(INS) r0(Operand1), r1(Operand2), r2(Operand3)  
// This_ instructions _set is basically adds r1 and r2 registers and writes the results into the r0 register.  
// ! r0 = r1+r2;  (in C)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;Some ARM instructions may also take some prefixes and suffixes.&lt;/p&gt;
&lt;h2&gt;Types of Instructions&lt;/h2&gt;
&lt;p&gt;ARM (Advanced RISC Machine) instructions can be broadly categorized into two primary types: &lt;strong&gt;Data Transfer and Process, Arithmetic and Logical Computation, and Barrel Control&lt;/strong&gt; operations. These categories encompass the fundamental operations that ARM processors perform to manipulate data and control the flow of information within a system.&lt;/p&gt;
&lt;h3&gt;Data Transfer and Process Instructions&lt;/h3&gt;
&lt;p&gt;These instructions are almost available in every microprocessor as well as in ARM microprocessors. These are very simple to use. Basically, provide to load or store the desired initial values to the register before processing. The instruction duty and usage structure are as follows.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MOV:&lt;/strong&gt; The &lt;code&gt;MOV&lt;/code&gt; instruction copies the value of &lt;code&gt;Operand2&lt;/code&gt; into &lt;code&gt;Rd&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MVN:&lt;/strong&gt; The &lt;code&gt;MVN&lt;/code&gt; instruction takes the value of &lt;code&gt;Operand2&lt;/code&gt;, performs a bitwise logical NOT operation on the value and places the result into &lt;code&gt;Rd&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Syntax:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;MOV{S}{cond} Rd, Operand2
MOV{cond} Rd, #imm16
MVN{S}{cond} Rd, Operand2
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;
We can assign a register value as well as we can assign a constant number.&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;MOV r0, r1    
MOV r0, 5  
MVN r0, r1  // r0 = NOT(r1)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;where:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;S: is an optional suffix. If S is specified, the condition code flags are updated on the result of the operation&lt;/li&gt;
&lt;li&gt;cond: is an optional condition code.&lt;/li&gt;
&lt;li&gt;Rd: is the destination register.&lt;/li&gt;
&lt;li&gt;Operand2: is a flexible second operand.&lt;/li&gt;
&lt;li&gt;imm 16: is any value in the range 0–65535. Immediate numbers are numerical constants.&lt;/li&gt;
&lt;/ul&gt;
&lt;h3&gt;Arithmetic and Logical Computation Instructions&lt;/h3&gt;
&lt;h4&gt;Arithmetic Computation Instructions&lt;/h4&gt;
&lt;p&gt;These instructions are fundamental arithmetic operations for all kinds of processors. They compute the sum (or difference), multiplication (or division)of two registers, and store the result in a register. Multiplication and division operations can also be performed via barrel shift.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;ADD:&lt;/strong&gt; The &lt;code&gt;ADD&lt;/code&gt; instruction adds the value of &lt;code&gt;Register1&lt;/code&gt; to&lt;code&gt;Register2&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SUB:&lt;/strong&gt; The &lt;code&gt;SUB&lt;/code&gt; instruction subtracts the value of &lt;code&gt;Register2&lt;/code&gt; from &lt;code&gt;Register1&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;MUL:&lt;/strong&gt; The &lt;code&gt;MUL&lt;/code&gt; instruction multiplies the value of &lt;code&gt;Register1&lt;/code&gt; by&lt;code&gt;Register2&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;SDIV:&lt;/strong&gt; The &lt;code&gt;SDIV&lt;/code&gt; instruction divides the value of &lt;code&gt;Register1&lt;/code&gt; by&lt;code&gt;Register2&lt;/code&gt;.&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;Note: Division with a constant number might not be supported by all ARM processors.
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Syntax:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;ADD{S}{cond} Register0, Register1, Register2
ADD Register1, #imm16  // 5
SUB{S}{cond} Register3, Register4, Register5
MUL Register0, Register1, Register2
SDIV Register3, Register4, Register5
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt;
&lt;p&gt;Given the following operations in the pseudocode:&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;result = (a + b) - (c + d);
a = b \* b;
c = d / e;
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;We can do the same operations with ARM instructions as follows:&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;// result = (a + b) - (c + d);
ADD   r0, r2, r3  // result = a + b;  (in C)
ADD   r1, r4, r5  // temp= c + d;  (in C)
SUB   r0, r0, r1  // result = result - temp;  (in C)
MUL r0, r2, r3    // a = b * c; (only 32 bits stored)  (in C)
SDIV  r0, r2, r4  // c = d / e; (signed divide)  (in C)
&lt;/code&gt;&lt;/pre&gt;

&lt;h4&gt;Logic Computation Instructions&lt;/h4&gt;
&lt;p&gt;The ARM instruction set provides instructions such as AND, OR, XOR, and BIC, which sets, and clears the bits according to the need of the program. Usually, you find these as part of if-else, while statements in high-level languages.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;AND:&lt;/strong&gt; The &lt;code&gt;AND&lt;/code&gt; instruction adds the value of &lt;code&gt;Register1&lt;/code&gt; to &lt;code&gt;Register2&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;OR:&lt;/strong&gt; The &lt;code&gt;OR&lt;/code&gt; instruction subtracts the value of &lt;code&gt;Register2&lt;/code&gt; from &lt;code&gt;Register1&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;XOR:&lt;/strong&gt; The &lt;code&gt;XOR&lt;/code&gt; instruction multiplies the value of &lt;code&gt;Register1&lt;/code&gt; by &lt;code&gt;Register2&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;BIC:&lt;/strong&gt; The &lt;code&gt;BIC&lt;/code&gt; instruction divides the value of &lt;code&gt;Register1&lt;/code&gt; by &lt;code&gt;Register2&lt;/code&gt;.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Syntax:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;AND Register0, Register1, Register2  // r0 = r1 &amp;amp; r2;  (in C)   
ORR Register3, Register4, Register5  // r3 = r4 | r5;  (in C)   
EOR Register0, Register1, Register2  // r0 = r1 ^ r2;  (in C)  
BIC Register3, Register4, Register5  // r3 = r4 &amp;amp; (!r5);  (in C)
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;&lt;strong&gt;Example:&lt;/strong&gt;&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;//  r0 = 01101001    
//  r1 = 11000111  
AND r3, r0, r1; r3  // 01000001  
ORR r3, r0, r1; r3  // 11101111   
EOR r3, r0, r1; r3  // 10101110   
BIC r3, r0, r1; r3  // 00101000
&lt;/code&gt;&lt;/pre&gt;

&lt;h3&gt;Branch Control Instructions&lt;/h3&gt;
&lt;p&gt;These instructions change the flow of execution via jumping to another instruction or subroutine  such as conditional jump e.g., branch if register == 0.&lt;/p&gt;
&lt;p&gt;&lt;strong&gt;Barrel Shifter:&lt;/strong&gt; As we mentioned in our first articles, the ARM’s arithmetic logic unit has a 32-bit barrel shifter that is capable of shifting and rotating operations. To be able to do this, the value must be in the register Rm. Briefly, the results are pre-processed by the barrel shifter before being processed in ALU.&lt;/p&gt;
&lt;pre class="codehilite"&gt;&lt;code&gt;MOV r0, r0, LSL #1  // Multiply r0 by two  
MOV r1, r1, LSR #2  // Divide r1 by four  
MOV r2, r2, ASR #2  // Divide r2 by four(signed).
&lt;/code&gt;&lt;/pre&gt;

&lt;p&gt;If you remember from digital electronic circuits, shifting a number 1 step left is equal to multiplying the number by 2. Shifting the number to 2 steps right means dividing the number by 4.&lt;/p&gt;
&lt;p&gt;The last column specifies how many cycle times each command takes. Although the basic logic of all barrel shifter instructions is the same, the only direction of shifting may vary. There are two types of usage of barrel shifters. These uses may be shifting by the value of any register or shifting by a specified fixed number.&lt;/p&gt;
&lt;p&gt;In the next article, I am planning to focus on the registers, CPU, and memory structure. Until then, I wish you no blue screen of death.&lt;/p&gt;
&lt;p&gt;Continue reading this series of articles:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://erdo.dev/posts/2019-01-24_Introduction-to-ARM-Architecture"&gt;Introduction to ARM Architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://erdo.dev/posts/2019-01-24_ARM-Development-Environment-Installation-ARM-Keil-Code-Composer-Studio"&gt;ARM Development Environment Installation: ARM Keil Code &amp;amp; Code Composer Studio&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;[1] &lt;a href="https://cseweb.ucsd.edu/classes/fa15/cse30/lectures/lec7_detailed.pdf"&gt;https://cseweb.ucsd.edu/classes/fa15/cse30/lectures/lec7_detailed.pdf&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href="http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.kui0100a/armasm_cihcjfjg.htm"&gt;http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.kui0100a/armasm_cihcjfjg.htm&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[3] &lt;a href="http://www.davespace.co.uk/arm/introduction-to-arm/barrel-shifter.html"&gt;http://www.davespace.co.uk/arm/introduction-to-arm/barrel-shifter.html&lt;/a&gt;&lt;/p&gt;</description><pubDate>Wed, 06 Mar 2019 12:00:00 GMT</pubDate></item><item><title>ARM Development Environment Installation: ARM Keil &amp; Code Composer Studio</title><link>https://www.erdo.dev/blog/2019-02-17_ARM-Development-Environment-Installation-ARM-Keil-Code-Composer-Studio/</link><description>&lt;h1&gt;ARM Development Environment Installation: ARM Keil &amp;amp; Code Composer Studio&lt;/h1&gt;
&lt;p&gt;17 Feb 2019&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/1*-OnOzyRgSQl9x64x2rlT7Q.png" /&gt;&lt;/p&gt;
&lt;p&gt;In the previous article, I said that for this article we’ll switch to writing code, but, I thought it would be more appropriate to give the programs that we can use for coding first. So I’m going to explain what program we’re going to use in this article by deferring the code writing to the next post.&lt;/p&gt;
&lt;p&gt;Since we use an ARM-based microcontroller called Stellaris LM4F120 we can use either ARM Keil or Texas Instrument's Code Composer Studio. I will show you how to install both ARM Keil and Code Composer Studio. For programming ARM processors, with C programming language or assembly, both of these two options are pretty good.&lt;/p&gt;
&lt;h2&gt;ARM Keil&lt;/h2&gt;
&lt;p&gt;Follow this section if you want to use ARM Keil as your IDE. Currently, the latest version is &lt;strong&gt;V5.26&lt;/strong&gt;, so I am going to continue with it.&lt;/p&gt;
&lt;p&gt;Go here for downloading; &lt;a href="https://www.keil.com/demo/eval/arm.htm#/DOWNLOAD"&gt;ARM Keil&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Right-click on MDK526.EXE and save it to your computer.&lt;/li&gt;
&lt;li&gt;Wait until downloads completely.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/1*qHOMyMZUsogF3sRYWmMW3g.png" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Run the MDK526.EXE file and click the next button.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/1*C0k2UY-SiiW8Rw_dxL0oPA.png" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Accept the Licence Agreement and then click the next button.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/1*cf9Du1sYpRVNe945nXdEdg.png" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Choose a setup directory.&lt;/li&gt;
&lt;li&gt;Make sure that there are no spaces in the directory names that go to the installation folder.&lt;/li&gt;
&lt;li&gt;Click the next button.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/1*trDewKPzBdxLTWtCdU2MtA.png" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Type the following fields and then click the next button.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/1*_hiGJSg7HARBWs3ANEguYA.png" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wait until installation is finished.&lt;/li&gt;
&lt;li&gt;After you see and click the finish button, you can click the Keil icon and run.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/1*yz0436215pz1JdS_hCUy9w.png" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Welcome to Arm Keil uVision5!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/1*3RiQe8J9xjMq4RYMZ0hnYg.png" /&gt;&lt;/p&gt;
&lt;p&gt;Here is a hint for you. When you want to create a project if you see your device is not in the devices list go to this &lt;a href="https://www.keil.com/dd2/pack/"&gt;link&lt;/a&gt; and download a particular device package that is suitable for your microcontroller.&lt;/p&gt;
&lt;p&gt;For my particular device, I downloaded the TI family package and executed it.&lt;/p&gt;
&lt;p&gt;Now our development medium is ready for new projects.&lt;/p&gt;
&lt;h2&gt;Code Composer Studio (CCS)&lt;/h2&gt;
&lt;p&gt;Follow this section if you want to use Code Composer Studio as your IDE. Currently, the latest version is &lt;strong&gt;8.3.0.00009&lt;/strong&gt;, so I am going to continue with it.&lt;/p&gt;
&lt;p&gt;Go here for downloading; &lt;a href="http://processors.wiki.ti.com/index.php/Download_CCS"&gt;CCS&lt;/a&gt;.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Make a selection according to your operating system.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/1*Sd3JysmRzKddIOU8aLonvg.png" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Unzip the WinRAR file that you have downloaded.&lt;/li&gt;
&lt;li&gt;Double-click on ccs_setup_8.3.0.0 and wait for the installation file to open.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/1*VeOcmlcbdEMTiGRCDSCMWQ.png" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;To ensure no problems occur during the installation, make sure that real-time anti-virus programs are turned off before proceeding with the installation.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/1*OkvpiiTCF9_x1qra_opx2A.png" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Accept the Licence Agreement and then click the next button.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/1*UIxxje0PGXTDLEqmLF04Qg.png" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Choose a setup directory.&lt;/li&gt;
&lt;li&gt;Make sure that there are no spaces in the directory names that go to the installation folder.&lt;/li&gt;
&lt;li&gt;Click the next button.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/1*yvX_tWwv4AJGoIkc8oQM8Q.png" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Select a product family that matches your own device.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/1*JkhTwnfQ65h_F2I63kbPTA.png" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Wait until the installation is finished it may take about half an hour.&lt;/li&gt;
&lt;li&gt;After you see and click the finish button, you can click the CCS icon and run.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/1*dA-wEAoGwipiefrLMzfEcQ.png" /&gt;
&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/1*x5Ao90N-XU57FB52sE_yrA.png" /&gt;&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Welcome to Code Composer Studio!&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/1*cZr_oKL4ucqIbZvO2DEU7A.png" /&gt;&lt;/p&gt;
&lt;p&gt;Now our development medium is ready for new projects. See you in next articles.&lt;/p&gt;
&lt;p&gt;Continue reading this series of articles:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://erdo.dev/posts/2019-01-24_Introduction-to-ARM-Architecture"&gt;Introduction to ARM Architecture&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://erdo.dev/posts/2019-07-06_ARM-Architecture-Instruction-Set"&gt;ARM Architecture Instruction Set&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;[1] &lt;a href="https://developer.arm.com/documentation/kan344/latest/Installation"&gt;https://developer.arm.com/documentation/kan344/latest/Installation&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href="https://software-dl.ti.com/ccs/esd/documents/users_guide_12.2.0/ccs_installation.html"&gt;https://software-dl.ti.com/ccs/esd/documents/users_guide_12.2.0/ccs_installation.html&lt;/a&gt;&lt;/p&gt;</description><pubDate>Sun, 17 Feb 2019 12:00:00 GMT</pubDate></item><item><title>Introduction to ARM Architecture</title><link>https://www.erdo.dev/blog/2019-01-24_Introduction-to-ARM-Architecture/</link><description>&lt;h1&gt;Introduction to ARM Architecture&lt;/h1&gt;
&lt;p&gt;24 Jan 2019&lt;/p&gt;
&lt;p&gt;&lt;img alt="The figure is taken from https://en.m.wikipedia.org/wiki/File:Acorn-ARM-Evaluation-System.jpg" src="https://cdn-images-1.medium.com/max/800/1*yVLT0ywWHW_PJ5VsiXNW9w.jpeg" /&gt;&lt;/p&gt;
&lt;p&gt;Anyone interested in embedded systems started to hear these two terms frequently. These are ARM and Embedded Linux. No longer, does everyone go towards work in these areas. Writing code in a free medium, when merging with the ease of getting rid of software licenses that cost millions, Embedded Linux started to gain popularity. As you all know, ARM architecture is very popular in the world and most projects use ARM-based processors with embedded systems.&lt;/p&gt;
&lt;p&gt;Throughout this article series, I would like to share my knowledge about ARM architecture and microprocessors that I learned during my exchange period at the Tampere University of Technology. While sharing the pieces of information I have learned, of course, I can make mistakes, also sometimes I can give incomplete information. Please feel free to contact me if you can correct the places you see wrong. After making our first explanations, let's get into the main topic.&lt;/p&gt;
&lt;h2&gt;What is ARM?&lt;/h2&gt;
&lt;p&gt;ARM is an architecture and its name refers to a company that invented ARM. This architecture was designed in 1983 by Acorn Computers Ltd. under the name of ARM1 (Acorn RISC Machine 1) and released in 1985. The following year, the company released 32-bit ARM2 and it created a tremendous impression with its simple and practical structure. In 1990, the company changed its name to Advanced RISC Machines Ltd. Later in 1998, the company changed its name again and ARM Ltd. is used today.&lt;/p&gt;
&lt;p&gt;In addition to its 32-bit architecture, its low cost has resulted in the creation of processor cores that are very popular today. ARM has been able to license the cores produced by various companies, thus enabling them to perform various applications. In other words, ARM does not produce an integrated circuit. Instead, many companies, such as Apple, Samsung, Hewlett-Packard, Qualcomm, Texas Instruments, NXP, Atmel, and STM have developed ARM kernels and improved their implementation, or launched their ARM-based processors.&lt;/p&gt;
&lt;p&gt;We will talk about ARM commands in our article series. C programming examples with ARM might take place, but for now, we will continue with the ARM instruction set. To get to know a microprocessor, I think it is possible to learn its instruction set and registers. If you already know C programming, you can use this information more effectively.&lt;/p&gt;
&lt;p&gt;ARM command sets are divided into 2 sub-sections, 16-bit THUMB, and 32-bit ARM instruction sets. We will first refer to 32-bit instruction sets. I do not intend to use any computer or board during this process, but if I can find the time, I can do a few complementary applications and share the images. The development kit I have in ARM applications is shown below.&lt;/p&gt;
&lt;p&gt;&lt;img alt="" src="https://cdn-images-1.medium.com/max/800/1*yIQPbYsexgheFMqO-n3lfA.jpeg" /&gt;&lt;/p&gt;
&lt;h2&gt;ARM’s Features&lt;/h2&gt;
&lt;p&gt;ARM is a RISC (Reduced Instruction Set Computer) class processor, ie the command set is a reduced processor. Let's explain why it's not exactly the RISC processor. Firstly it has 32-bit registers from r1 to r16, and we can control all instruction sets conditionally. Also, it has a 32-bit barrel shifter, which is known as a combinational circuit, ie it allows several operations in a clock pulse independent from the clock signal. All these features do not make the ARM processors fully RISC-class microprocessors.
The ARM has a total of seven operating modes.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Use Mode&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Fast Interrupt (FIQ) Mode&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Interrupt (IRQ) Mode&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Supervisor Mode&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Abort Mode&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;System Mode&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;li&gt;
&lt;ol&gt;
&lt;li&gt;Undefined Mode&lt;/li&gt;
&lt;/ol&gt;
&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;The ARM consists of thirty-seven registers. The registers are arranged in partially overlapping banks. There is a different register bank for each processor mode. These registers are not all accessible at the same time. The processor state and operating mode determine which registers are available to the programmer.&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;Thirty-one of these registers have 32-bit general-purpose registers,&lt;/li&gt;
&lt;li&gt;Six are status registers,&lt;/li&gt;
&lt;li&gt;The ARM-state register set contains sixteen directly accessible (programmer-capable) registers, r0 to r15.&lt;/li&gt;
&lt;/ul&gt;
&lt;p&gt;In general, ARM has a small-endian system but can be set as big-endian if desired.&lt;/p&gt;
&lt;p&gt;I think it’s enough for today. In the next article, we will touch on technical issues. In order to better understand, it is useful for the readers to reinforce their knowledge by repeating terms such as RISC, Registers, Little Endian and Big Endian. See you in our next articles.&lt;/p&gt;
&lt;p&gt;Continue reading this series of articles:&lt;/p&gt;
&lt;ul&gt;
&lt;li&gt;&lt;a href="https://erdo.dev/posts/2019-01-24_ARM-Development-Environment-Installation-ARM-Keil-Code-Composer-Studio"&gt;ARM Development Environment Installation: ARM Keil &amp;amp; Code Composer Studio&lt;/a&gt;&lt;/li&gt;
&lt;li&gt;&lt;a href="https://erdo.dev/posts/2019-07-06_ARM-Architecture-Instruction-Set"&gt;ARM Architecture Instruction Set&lt;/a&gt;&lt;/li&gt;
&lt;/ul&gt;
&lt;h2&gt;References&lt;/h2&gt;
&lt;p&gt;[1] &lt;a href="https://en.wikipedia.org/wiki/ARM_architecture"&gt;https://en.wikipedia.org/wiki/ARM_architecture&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[2] &lt;a href="https://en.wikipedia.org/wiki/Arm_Holdings"&gt;https://en.wikipedia.org/wiki/Arm_Holdings&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[3] &lt;a href="http://www.keil.com/support/man/docs/armasm/armasm_dom1359731128950.htm"&gt;http://www.keil.com/support/man/docs/armasm/armasm_dom1359731128950.htm&lt;/a&gt;&lt;/p&gt;
&lt;p&gt;[4] &lt;a href="http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.ddi0210c/Cihhcjia.html"&gt;http://infocenter.arm.com/help/index.jsp?topic=/com.arm.doc.ddi0210c/Cihhcjia.html&lt;/a&gt;&lt;/p&gt;</description><pubDate>Thu, 24 Jan 2019 12:00:00 GMT</pubDate></item></channel></rss>